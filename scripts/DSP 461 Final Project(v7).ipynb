{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22033,
     "status": "ok",
     "timestamp": 1575499850650,
     "user": {
      "displayName": "Joseph Erickson",
      "photoUrl": "",
      "userId": "18197697941711049711"
     },
     "user_tz": 300
    },
    "id": "ZXLMLqmhqGqt",
    "outputId": "3a30e37b-1063-4ffd-f6ec-8c1bb5f3de79"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#mount your drive.  Complete Oauth to authenticate\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqJt5FExqfYg"
   },
   "outputs": [],
   "source": [
    "#unzip image folder\n",
    "#!unzip -uq \"/content/gdrive/My Drive/jpegs.zip\" -d \"/content/gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762645,
     "status": "error",
     "timestamp": 1575500591286,
     "user": {
      "displayName": "Joseph Erickson",
      "photoUrl": "",
      "userId": "18197697941711049711"
     },
     "user_tz": 300
    },
    "id": "xC81Yd_KrO5M",
    "outputId": "b4b60ce5-eaca-4946-c9db-c4adb81f744f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Train our network\n",
    "def train_network(epochs, val_percent, train_batch_size, test_batch_size, eval_freq):\n",
    "    \n",
    "    print('Beginning setup...')\n",
    "\n",
    "    # Training set values (same for all data)\n",
    "    data_means = [0.6786, 0.6413, 0.6605]\n",
    "    data_stds = [0.2012, 0.2080, 0.1997]\n",
    "\n",
    "    transformations = transforms.Compose([\n",
    "        transforms.Resize((30,40),2),    # Resizes to 1/16 the size of the original image for speed.\n",
    "    #    transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),  # Transforms channels from 0- 255 -> 0-1.\n",
    "        transforms.Normalize(mean=data_means, std=data_stds)])\n",
    "\n",
    "    #epochs = 10\n",
    "    #val_percent = 0.2\n",
    "    #train_batch_size = 25\n",
    "    #test_batch_size = 25\n",
    "    #eval_freq = 1\n",
    "\n",
    "    # Can choose various loss functions to use:\n",
    "    criterion = nn.NLLLoss()\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "    \n",
    "    print(\"Setting up train, test, and validation sets...\")\n",
    "\n",
    "    #full_train_set = datasets.ImageFolder(\"/content/gdrive/My Drive/TRAIN\", transform=transformations)\n",
    "    full_train_set = datasets.ImageFolder(\"./jpegs/TRAIN\", transform=transformations)\n",
    "    #full_train_set, temp = torch.utils.data.random_split(full_train_set, [int(len(full_train_set) / 20), len(full_train_set) - int(len(full_train_set) / 20)])\n",
    "    full_train_loader = torch.utils.data.DataLoader(full_train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    print(\"Full train set size: \", len(full_train_set))\n",
    "\n",
    "    val_size = int(len(full_train_set)*val_percent)\n",
    "    train_set, val_set = torch.utils.data.random_split(full_train_set, [len(full_train_set) - val_size, val_size])\n",
    "    print(\"Train set size: \", len(train_set))\n",
    "    print(\"Validation set size: \", len(val_set))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    #test_set = datasets.ImageFolder(\"/content/gdrive/My Drive/TEST\", transform=transformations)\n",
    "    test_set = datasets.ImageFolder(\"./jpegs/TEST\", transform=transformations)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size, shuffle=True)\n",
    "    print(\"Test set size: \", len(test_set))\n",
    "\n",
    "    # Options: MOST GENERALIZED - 121, 169, 201, 161 - MOST ACCURATE\n",
    "    # https://pytorch.org/hub/pytorch_vision_densenet/\n",
    "    model = models.densenet161(pretrained=True)\n",
    "\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    classifier_input = model.classifier.in_features\n",
    "    num_labels = 4\n",
    "    classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(1024, 512),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(512, num_labels),\n",
    "                               nn.LogSoftmax(dim=1))\n",
    "\n",
    "\n",
    "    model.classifier = classifier\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set the optimizer function using torch.optim as optim library\n",
    "    optimizer = optim.Adam(model.classifier.parameters())\n",
    "    \n",
    "    print(\"Beginning training...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        # Training the model\n",
    "        model.train()\n",
    "        counter = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            # Move to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Clear optimizers\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            output = model.forward(inputs)\n",
    "            # Loss\n",
    "            loss = criterion(output, labels)\n",
    "            # Calculate gradients (backpropogation)\n",
    "            loss.backward()\n",
    "            # Adjust parameters based on gradients\n",
    "            optimizer.step()\n",
    "            # Add the loss to the training set's rnning loss\n",
    "            train_loss += loss.item()*inputs.size(0)\n",
    "\n",
    "            # Print the progress of our training\n",
    "            counter += 1\n",
    "            #print(counter, \"/\", len(train_loader))\n",
    "            sys.stdout.write(\"\\rTraining...({}/{})\".format(counter, len(train_loader)))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if (epoch % eval_freq == 0):\n",
    "    \n",
    "            print(\"\")\n",
    "\n",
    "            # Evaluating the model\n",
    "            model.eval()\n",
    "            counter = 0\n",
    "            # Tell torch not to calculate gradients\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    # Move to device\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    # Forward pass\n",
    "                    output = model.forward(inputs)\n",
    "                    # Calculate Loss\n",
    "                    valloss = criterion(output, labels)\n",
    "                    # Add loss to the validation set's running loss\n",
    "                    val_loss += valloss.item()*inputs.size(0)\n",
    "\n",
    "                    # Since our model outputs a LogSoftmax, find the real\n",
    "                    # percentages by reversing the log function\n",
    "                    output = torch.exp(output)\n",
    "                    # Get the top class of the output\n",
    "                    top_p, top_class = output.topk(1, dim=1)\n",
    "                    # See how many of the classes were correct?\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    # Calculate the mean (get the accuracy for this batch)\n",
    "                    # and add it to the running accuracy for this epoch\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                    # Print the progress of our evaluation\n",
    "                    counter += 1\n",
    "                    #print(counter, \"/\", len(val_loader))\n",
    "                    sys.stdout.write(\"\\rValidating... ({}/{})\".format(counter, len(val_loader)))\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            # Get the average loss for the entire epoch\n",
    "            train_loss = train_loss/len(train_loader.dataset)\n",
    "            val_loss = val_loss/len(val_loader.dataset)\n",
    "            accuracy = accuracy/len(val_loader)\n",
    "            # Print out the information\n",
    "            print('\\nEpoch: {} \\tAccuracy: {:.6f} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} '.format(epoch+1, accuracy, train_loss, val_loss))\n",
    "\n",
    "\n",
    "\n",
    "    full_train_loss = 0\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    # Training the model one final time on the full dataset\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    for inputs, labels in full_train_loader:\n",
    "        # Move to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Clear optimizers\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model.forward(inputs)\n",
    "        # Loss\n",
    "        loss = criterion(output, labels)\n",
    "        # Calculate gradients (backpropogation)\n",
    "        loss.backward()\n",
    "        # Adjust parameters based on gradients\n",
    "        optimizer.step()\n",
    "        # Add the loss to the training set's rnning loss\n",
    "        full_train_loss += loss.item()*inputs.size(0)\n",
    "\n",
    "        # Print the progress of our training\n",
    "        counter += 1\n",
    "        #print(counter, \"/\", len(full_train_loader))\n",
    "        sys.stdout.write(\"\\rTraining... ({}/{})\".format(counter, len(full_train_loader)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # Saving the model\n",
    "    #torch.save(model, \"./blood_model.py\")\n",
    "    torch.save(model, \"./blood_model_e{}_v{}_b{}.py\".format(epochs, val_percent, train_batch_size))\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    # Tell torch not to calculate gradients\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Move to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            output = model.forward(inputs)\n",
    "            # Calculate Loss\n",
    "            testloss = criterion(output, labels)\n",
    "            # Add loss to the validation set's running loss\n",
    "            test_loss += testloss.item()*inputs.size(0)\n",
    "\n",
    "            # Since our model outputs a LogSoftmax, find the real\n",
    "            # percentages by reversing the log function\n",
    "            output = torch.exp(output)\n",
    "            # Get the top class of the output\n",
    "            top_p, top_class = output.topk(1, dim=1)\n",
    "            # See how many of the classes were correct?\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "            # Calculate the mean (get the accuracy for this batch)\n",
    "            # and add it to the running accuracy for this epoch\n",
    "            test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            # Print the progress of our evaluation\n",
    "            counter += 1\n",
    "            #print(counter, \"/\", len(test_loader))\n",
    "            sys.stdout.write(\"\\rTesting...({}/{})\".format(counter, len(test_loader)))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    # Get the average loss for the entire fold\n",
    "    full_train_loss = full_train_loss/len(full_train_loader.dataset)\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    test_accuracy = test_accuracy/len(test_loader)\n",
    "    # Print out the information\n",
    "    #print('Test Set Accuracy: ', test_accuracy)\n",
    "    print('\\nFinal Results:\\tAccuracy: {:.6f} \\tTraining Loss: {:.6f} \\tTesting Loss: {:.6f} \\n'.format(test_accuracy, full_train_loss, test_loss))\n",
    "\n",
    "\n",
    "# Process our image\n",
    "def process_image(image_path):\n",
    "    # Load Image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    width, height = img.size\n",
    "\n",
    "    # Resize by keeping the aspect ratio, but changing the dimension\n",
    "    # so the shortest size is 255px\n",
    "    # img = img.resize((255, int(255*(height/width))) if width < height else (int(255*(width/height)), 255))\n",
    "\n",
    "    # Get the dimensions of the new image size\n",
    "    width, height = img.size\n",
    "\n",
    "    # Set the coordinates to do a center crop of 224 x 224\n",
    "    #left = (width - 224)/2\n",
    "    #top = (height - 224)/2\n",
    "    #right = (width + 224)/2\n",
    "    #bottom = (height + 224)/2\n",
    "    #img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # Turn image into numpy array\n",
    "    img = np.array(img)\n",
    "\n",
    "    # Make the color channel dimension first instead of last\n",
    "    img = img.transpose((2, 0, 1))\n",
    "\n",
    "    # Make all values between 0 and 1\n",
    "    img = img/255\n",
    "\n",
    "    # Normalize based on the preset mean and standard deviation\n",
    "    img[0] = (img[0] - data_means[0])/data_stds[0]\n",
    "    img[1] = (img[1] - data_means[1])/data_stds[1]\n",
    "    img[2] = (img[2] - data_means[2])/data_stds[2]\n",
    "\n",
    "    # Add a fourth dimension to the beginning to indicate batch size\n",
    "    img = img[np.newaxis,:]\n",
    "\n",
    "    # Turn into a torch tensor\n",
    "    image = torch.from_numpy(img)\n",
    "    image = image.float()\n",
    "    return image\n",
    "\n",
    "# Using our model to predict the label\n",
    "def predict(image, model):\n",
    "    # Pass the image through our model\n",
    "    output = model.forward(image)\n",
    "\n",
    "    # Reverse the log function in our output\n",
    "    output = torch.exp(output)\n",
    "\n",
    "    # Get the top predicted class, and the output percentage for\n",
    "    # that class\n",
    "    probs, classes = output.topk(1, dim=1)\n",
    "    return probs.item(), classes.item()\n",
    "\n",
    "# Show Image\n",
    "def show_image(image):\n",
    "    # Convert image to numpy\n",
    "    image = image.numpy()\n",
    "\n",
    "    # Un-normalize the image with avg std and mean\n",
    "    image[0] = image[0] * 0.2030 + 0.6601\n",
    "\n",
    "    # Print the image\n",
    "    fig = plt.figure(figsize=(25, 4))\n",
    "    plt.imshow(np.transpose(image[0], (1, 2, 0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss Function: NLLLoss \tNumber of Epochs: 25 \tBatch Size: 50 \tValidation Percent: 0.2\n",
      "Images resized to 30x40px.\n",
      "Beginning setup...\n",
      "Setting up train, test, and validation sets...\n",
      "Full train set size:  9957\n",
      "Train set size:  7966\n",
      "Validation set size:  1991\n",
      "Test set size:  2487\n",
      "Beginning training...\n",
      "160/160\n",
      "40/40Epoch: 1 \tAccuracy: 0.578183 \tTraining Loss: 1.142643 \tValidation Loss: 1.174141 \n",
      "\n",
      "Epoch: 2 \tAccuracy: 0.611354 \tTraining Loss: 0.928256 \tValidation Loss: 1.119942 \n",
      "\n",
      "Epoch: 3 \tAccuracy: 0.609366 \tTraining Loss: 0.877490 \tValidation Loss: 1.056922 \n",
      "\n",
      "Epoch: 4 \tAccuracy: 0.648524 \tTraining Loss: 0.810964 \tValidation Loss: 0.945965 \n",
      "\n",
      "Epoch: 5 \tAccuracy: 0.663963 \tTraining Loss: 0.767143 \tValidation Loss: 0.851936 \n",
      "\n",
      "Epoch: 6 \tAccuracy: 0.656183 \tTraining Loss: 0.728475 \tValidation Loss: 0.917637 \n",
      "\n",
      "Epoch: 7 \tAccuracy: 0.671244 \tTraining Loss: 0.658943 \tValidation Loss: 0.834392 \n",
      "\n",
      "Epoch: 8 \tAccuracy: 0.671963 \tTraining Loss: 0.630438 \tValidation Loss: 1.083430 \n",
      "\n",
      "Epoch: 9 \tAccuracy: 0.691573 \tTraining Loss: 0.599128 \tValidation Loss: 0.809292 \n",
      "\n",
      "Epoch: 10 \tAccuracy: 0.689634 \tTraining Loss: 0.577902 \tValidation Loss: 0.809140 \n",
      "\n",
      "Epoch: 11 \tAccuracy: 0.706293 \tTraining Loss: 0.540616 \tValidation Loss: 0.750232 \n",
      "\n",
      "Epoch: 12 \tAccuracy: 0.709073 \tTraining Loss: 0.508739 \tValidation Loss: 0.764912 \n",
      "\n",
      "Epoch: 13 \tAccuracy: 0.693463 \tTraining Loss: 0.481986 \tValidation Loss: 0.837876 \n",
      "\n",
      "Epoch: 14 \tAccuracy: 0.707573 \tTraining Loss: 0.453824 \tValidation Loss: 0.837251 \n",
      "\n",
      "Epoch: 15 \tAccuracy: 0.720012 \tTraining Loss: 0.440873 \tValidation Loss: 0.783549 \n",
      "\n",
      "Epoch: 16 \tAccuracy: 0.714683 \tTraining Loss: 0.421703 \tValidation Loss: 0.721325 \n",
      "\n",
      "Epoch: 17 \tAccuracy: 0.702854 \tTraining Loss: 0.415654 \tValidation Loss: 0.858572 \n",
      "\n",
      "Epoch: 18 \tAccuracy: 0.711012 \tTraining Loss: 0.381752 \tValidation Loss: 0.857654 \n"
     ]
    }
   ],
   "source": [
    "t_epochs = [25,50,100,200,400]\n",
    "t_batches = [50,100,200,400,800]\n",
    "t_val = 0.2\n",
    "\n",
    "for i in t_epochs:\n",
    "    for j in t_batches:\n",
    "        print('\\nLoss Function: NLLLoss \\tNumber of Epochs: {} \\tBatch Size: {} \\tValidation Percent: {}'.format(i,j,t_val))\n",
    "        print('Images resized to 30x40px.')\n",
    "        train_network(epochs=i, val_percent=t_val, train_batch_size=j, test_batch_size=j, eval_freq=1)\n",
    "\n",
    "#train_network(epochs=3, val_percent=0.2, train_batch_size=25, test_batch_size=25, eval_freq=1)\n",
    "\n",
    "#epochs = 10\n",
    "#val_percent = 0.2\n",
    "#train_batch_size = 25\n",
    "#test_batch_size = 25\n",
    "#eval_freq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Sv8vq8UPnTHv",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957 9957\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-cdebca498805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mfull_train_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_train_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpreds_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_num_correct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_train_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_train_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-cdebca498805>\u001b[0m in \u001b[0;36mget_all_preds\u001b[1;34m(model, loader)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         all_preds = torch.cat(\n\u001b[0;32m     11\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"
     ]
    }
   ],
   "source": [
    "'''print(len(full_train_set),len(full_train_set.targets))\n",
    "\n",
    "# https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds\n",
    "\n",
    "with torch.no_grad():\n",
    "    full_train_preds = get_all_preds(model, full_train_loader)\n",
    "    \n",
    "preds_correct = get_num_correct(full_train_preds, full_train_set.targets)\n",
    "\n",
    "print('total correct:', preds_correct)\n",
    "print('accuracy:', preds_correct / len(full_train_set))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================>"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "for i in range(30):\n",
    "    sys.stdout.write(\"\\r{}>\".format(\"=\"*i))\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "text",
    "id": "U71Msd6msj_7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Run 1\n",
    "\n",
    "epochs = 10\n",
    "val_percent = 0.2\n",
    "train_batch_size = 25\n",
    "test_batch_size = 25\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "\n",
    "\n",
    "Epoch: 1 \tAccuracy: 0.792156 \tTraining Loss: 0.866748 \tValidation Loss: 0.507381 \n",
    "Epoch: 2 \tAccuracy: 0.828156 \tTraining Loss: 0.480419 \tValidation Loss: 0.436654 \n",
    "Epoch: 3 \tAccuracy: 0.832219 \tTraining Loss: 0.411089 \tValidation Loss: 0.421812 \n",
    "Epoch: 4 \tAccuracy: 0.882937 \tTraining Loss: 0.364378 \tValidation Loss: 0.311798 \n",
    "Epoch: 5 \tAccuracy: 0.884000 \tTraining Loss: 0.334123 \tValidation Loss: 0.299411 \n",
    "Epoch: 6 \tAccuracy: 0.839937 \tTraining Loss: 0.283902 \tValidation Loss: 0.376899 \n",
    "Epoch: 7 \tAccuracy: 0.897500 \tTraining Loss: 0.245882 \tValidation Loss: 0.265919 \n",
    "Epoch: 8 \tAccuracy: 0.845719 \tTraining Loss: 0.243905 \tValidation Loss: 0.433223 \n",
    "Epoch: 9 \tAccuracy: 0.909000 \tTraining Loss: 0.221514 \tValidation Loss: 0.226245 \n",
    "Epoch: 10 \tAccuracy: 0.908156 \tTraining Loss: 0.224361 \tValidation Loss: 0.237138 \n",
    "\n",
    "Test Set Accuracy:  0.609033337533474\n",
    "Training Loss: 0.214690 \tTesting Loss: 1.398789\n",
    "\n",
    "\n",
    "Run 2\n",
    "\n",
    "epochs = 5\n",
    "val_percent = 0.2\n",
    "train_batch_size = 25\n",
    "test_batch_size = 25\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "Number of Epochs 5 \tBatch Size: 25\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.817156 \tTraining Loss: 0.333088 \tValidation Loss: 0.141337 \n",
    "Epoch: 2 \tAccuracy: 0.853875 \tTraining Loss: 0.156773 \tValidation Loss: 0.105850 \n",
    "Epoch: 3 \tAccuracy: 0.820438 \tTraining Loss: 0.125960 \tValidation Loss: 0.134789 \n",
    "Epoch: 4 \tAccuracy: 0.890937 \tTraining Loss: 0.112367 \tValidation Loss: 0.081046 \n",
    "Epoch: 5 \tAccuracy: 0.889656 \tTraining Loss: 0.090118 \tValidation Loss: 0.069279 \n",
    "Final Results:\tAccuracy: 0.633100 \tTraining Loss: 0.091679 \tTesting Loss: 0.378427 \n",
    "\n",
    "\n",
    "Run 3\n",
    "\n",
    "epochs = 5\n",
    "val_percent = 0.2\n",
    "train_batch_size = 50\n",
    "test_batch_size = 50\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "Number of Epochs 5 \tBatch Size: 50\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.706902 \tTraining Loss: 0.338026 \tValidation Loss: 0.219773 \n",
    "Epoch: 2 \tAccuracy: 0.845341 \tTraining Loss: 0.151417 \tValidation Loss: 0.110280 \n",
    "Epoch: 3 \tAccuracy: 0.805622 \tTraining Loss: 0.117722 \tValidation Loss: 0.149176 \n",
    "Epoch: 4 \tAccuracy: 0.883841 \tTraining Loss: 0.100289 \tValidation Loss: 0.079365 \n",
    "Epoch: 5 \tAccuracy: 0.869232 \tTraining Loss: 0.081888 \tValidation Loss: 0.091883 \n",
    "Final Results:\tAccuracy: 0.611351 \tTraining Loss: 0.078182 \tTesting Loss: 0.523621 \n",
    "\n",
    "\n",
    "Run 4\n",
    "\n",
    "epochs = 10\n",
    "val_percent = 0.2\n",
    "train_batch_size = 10\n",
    "test_batch_size = 10\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 10 \tBatch Size: 10\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.690500 \tTraining Loss: 0.365573 \tValidation Loss: 0.235582 \n",
    "Epoch: 2 \tAccuracy: 0.812500 \tTraining Loss: 0.201150 \tValidation Loss: 0.147381 \n",
    "Epoch: 3 \tAccuracy: 0.730000 \tTraining Loss: 0.181403 \tValidation Loss: 0.185218 \n",
    "Epoch: 4 \tAccuracy: 0.854500 \tTraining Loss: 0.151453 \tValidation Loss: 0.107096 \n",
    "Epoch: 5 \tAccuracy: 0.816000 \tTraining Loss: 0.146963 \tValidation Loss: 0.143466 \n",
    "Epoch: 6 \tAccuracy: 0.904500 \tTraining Loss: 0.124523 \tValidation Loss: 0.063926 \n",
    "Epoch: 7 \tAccuracy: 0.901000 \tTraining Loss: 0.118210 \tValidation Loss: 0.067525 \n",
    "Epoch: 8 \tAccuracy: 0.899500 \tTraining Loss: 0.106047 \tValidation Loss: 0.071042 \n",
    "Epoch: 9 \tAccuracy: 0.882500 \tTraining Loss: 0.106182 \tValidation Loss: 0.090328 \n",
    "Epoch: 10 \tAccuracy: 0.918000 \tTraining Loss: 0.100359 \tValidation Loss: 0.055422 \n",
    "Final Results:\tAccuracy: 0.579575 \tTraining Loss: 0.099168 \tTesting Loss: 0.497934 \n",
    "\n",
    "\n",
    "Run 5\n",
    "\n",
    "epochs = 10\n",
    "val_percent = 0.2\n",
    "train_batch_size = 25\n",
    "test_batch_size = 25\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 10 \tBatch Size: 25\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.775875 \tTraining Loss: 0.369764 \tValidation Loss: 0.174198 \n",
    "Epoch: 2 \tAccuracy: 0.864375 \tTraining Loss: 0.147204 \tValidation Loss: 0.094772 \n",
    "Epoch: 3 \tAccuracy: 0.861937 \tTraining Loss: 0.128951 \tValidation Loss: 0.096287 \n",
    "Epoch: 4 \tAccuracy: 0.683875 \tTraining Loss: 0.115682 \tValidation Loss: 0.249141 \n",
    "Epoch: 5 \tAccuracy: 0.864500 \tTraining Loss: 0.102457 \tValidation Loss: 0.099864 \n",
    "Epoch: 6 \tAccuracy: 0.859656 \tTraining Loss: 0.104447 \tValidation Loss: 0.105911 \n",
    "Epoch: 7 \tAccuracy: 0.893437 \tTraining Loss: 0.084532 \tValidation Loss: 0.072831 \n",
    "Epoch: 8 \tAccuracy: 0.891719 \tTraining Loss: 0.068216 \tValidation Loss: 0.078928 \n",
    "Epoch: 9 \tAccuracy: 0.915500 \tTraining Loss: 0.072132 \tValidation Loss: 0.054932 \n",
    "Epoch: 10 \tAccuracy: 0.892437 \tTraining Loss: 0.064584 \tValidation Loss: 0.071456 \n",
    "Final Results:\tAccuracy: 0.591733 \tTraining Loss: 0.059329 \tTesting Loss: 0.465852 \n",
    "\n",
    "\n",
    "Run 6\n",
    "\n",
    "epochs = 10\n",
    "val_percent = 0.2\n",
    "train_batch_size = 50\n",
    "test_batch_size = 50\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 10 \tBatch Size: 50\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.809841 \tTraining Loss: 0.356934 \tValidation Loss: 0.159654 \n",
    "Epoch: 2 \tAccuracy: 0.802841 \tTraining Loss: 0.167494 \tValidation Loss: 0.161009 \n",
    "Epoch: 3 \tAccuracy: 0.878280 \tTraining Loss: 0.128304 \tValidation Loss: 0.088309 \n",
    "Epoch: 4 \tAccuracy: 0.898061 \tTraining Loss: 0.102006 \tValidation Loss: 0.071432 \n",
    "Epoch: 5 \tAccuracy: 0.871451 \tTraining Loss: 0.081752 \tValidation Loss: 0.087102 \n",
    "Epoch: 6 \tAccuracy: 0.893671 \tTraining Loss: 0.073098 \tValidation Loss: 0.072326 \n",
    "Epoch: 7 \tAccuracy: 0.831622 \tTraining Loss: 0.073735 \tValidation Loss: 0.115225 \n",
    "Epoch: 8 \tAccuracy: 0.899232 \tTraining Loss: 0.063430 \tValidation Loss: 0.066452 \n",
    "Epoch: 9 \tAccuracy: 0.787622 \tTraining Loss: 0.057203 \tValidation Loss: 0.141842 \n",
    "Epoch: 10 \tAccuracy: 0.906061 \tTraining Loss: 0.051924 \tValidation Loss: 0.061586 \n",
    "Final Results:\tAccuracy: 0.585232 \tTraining Loss: 0.054685 \tTesting Loss: 0.605523 \n",
    "\n",
    "\n",
    "Run 7\n",
    "\n",
    "epochs = 25\n",
    "val_percent = 0.2\n",
    "train_batch_size = 10\n",
    "test_batch_size = 10\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 25 \tBatch Size: 10\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.757000 \tTraining Loss: 0.375817 \tValidation Loss: 0.186139 \n",
    "Epoch: 2 \tAccuracy: 0.795000 \tTraining Loss: 0.205320 \tValidation Loss: 0.152541 \n",
    "Epoch: 3 \tAccuracy: 0.880500 \tTraining Loss: 0.176783 \tValidation Loss: 0.086798 \n",
    "Epoch: 4 \tAccuracy: 0.843500 \tTraining Loss: 0.144934 \tValidation Loss: 0.110221 \n",
    "Epoch: 5 \tAccuracy: 0.863500 \tTraining Loss: 0.142000 \tValidation Loss: 0.101107 \n",
    "Epoch: 6 \tAccuracy: 0.884500 \tTraining Loss: 0.133002 \tValidation Loss: 0.080656 \n",
    "Epoch: 7 \tAccuracy: 0.875500 \tTraining Loss: 0.124930 \tValidation Loss: 0.088253 \n",
    "Epoch: 8 \tAccuracy: 0.894500 \tTraining Loss: 0.120515 \tValidation Loss: 0.071422 \n",
    "Epoch: 9 \tAccuracy: 0.910000 \tTraining Loss: 0.111565 \tValidation Loss: 0.064102 \n",
    "Epoch: 10 \tAccuracy: 0.880000 \tTraining Loss: 0.095075 \tValidation Loss: 0.092609 \n",
    "Epoch: 11 \tAccuracy: 0.895500 \tTraining Loss: 0.092246 \tValidation Loss: 0.075103 \n",
    "Epoch: 12 \tAccuracy: 0.877500 \tTraining Loss: 0.090711 \tValidation Loss: 0.086725 \n",
    "Epoch: 13 \tAccuracy: 0.923000 \tTraining Loss: 0.079825 \tValidation Loss: 0.051033 \n",
    "Epoch: 14 \tAccuracy: 0.915500 \tTraining Loss: 0.079019 \tValidation Loss: 0.061295 \n",
    "Epoch: 15 \tAccuracy: 0.875500 \tTraining Loss: 0.075476 \tValidation Loss: 0.085533 \n",
    "Epoch: 16 \tAccuracy: 0.926500 \tTraining Loss: 0.070708 \tValidation Loss: 0.047325 \n",
    "Epoch: 17 \tAccuracy: 0.921500 \tTraining Loss: 0.067846 \tValidation Loss: 0.053646 \n",
    "Epoch: 18 \tAccuracy: 0.929500 \tTraining Loss: 0.063120 \tValidation Loss: 0.049539 \n",
    "Epoch: 19 \tAccuracy: 0.927000 \tTraining Loss: 0.069536 \tValidation Loss: 0.044894 \n",
    "Epoch: 20 \tAccuracy: 0.908000 \tTraining Loss: 0.057740 \tValidation Loss: 0.058151 \n",
    "Epoch: 21 \tAccuracy: 0.931500 \tTraining Loss: 0.062402 \tValidation Loss: 0.044121 \n",
    "Epoch: 22 \tAccuracy: 0.899500 \tTraining Loss: 0.055306 \tValidation Loss: 0.065437 \n",
    "Epoch: 23 \tAccuracy: 0.937500 \tTraining Loss: 0.053638 \tValidation Loss: 0.038308 \n",
    "Epoch: 24 \tAccuracy: 0.877500 \tTraining Loss: 0.056319 \tValidation Loss: 0.089545 \n",
    "Epoch: 25 \tAccuracy: 0.938000 \tTraining Loss: 0.051920 \tValidation Loss: 0.040229 \n",
    "Final Results:\tAccuracy: 0.585083 \tTraining Loss: 0.057713 \tTesting Loss: 0.539717 \n",
    "\n",
    "\n",
    "Run 8\n",
    "\n",
    "epochs = 25\n",
    "val_percent = 0.2\n",
    "train_batch_size = 25\n",
    "test_batch_size = 25\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 25 \tBatch Size: 25\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.776719 \tTraining Loss: 0.350825 \tValidation Loss: 0.159253 \n",
    "Epoch: 2 \tAccuracy: 0.852656 \tTraining Loss: 0.161037 \tValidation Loss: 0.111297 \n",
    "Epoch: 3 \tAccuracy: 0.889719 \tTraining Loss: 0.132416 \tValidation Loss: 0.083140 \n",
    "Epoch: 4 \tAccuracy: 0.830875 \tTraining Loss: 0.113532 \tValidation Loss: 0.119885 \n",
    "Epoch: 5 \tAccuracy: 0.894937 \tTraining Loss: 0.107010 \tValidation Loss: 0.078021 \n",
    "Epoch: 6 \tAccuracy: 0.866656 \tTraining Loss: 0.088975 \tValidation Loss: 0.106714 \n",
    "Epoch: 7 \tAccuracy: 0.867937 \tTraining Loss: 0.092737 \tValidation Loss: 0.088912 \n",
    "Epoch: 8 \tAccuracy: 0.916219 \tTraining Loss: 0.082230 \tValidation Loss: 0.060523 \n",
    "Epoch: 9 \tAccuracy: 0.910937 \tTraining Loss: 0.069651 \tValidation Loss: 0.057465 \n",
    "Epoch: 10 \tAccuracy: 0.903937 \tTraining Loss: 0.061174 \tValidation Loss: 0.070802 \n",
    "Epoch: 11 \tAccuracy: 0.921719 \tTraining Loss: 0.056615 \tValidation Loss: 0.054289 \n",
    "Epoch: 12 \tAccuracy: 0.920437 \tTraining Loss: 0.050735 \tValidation Loss: 0.052366 \n",
    "Epoch: 13 \tAccuracy: 0.914437 \tTraining Loss: 0.055098 \tValidation Loss: 0.056898 \n",
    "Epoch: 14 \tAccuracy: 0.934719 \tTraining Loss: 0.051010 \tValidation Loss: 0.045074 \n",
    "Epoch: 15 \tAccuracy: 0.935500 \tTraining Loss: 0.047064 \tValidation Loss: 0.045387 \n",
    "Epoch: 16 \tAccuracy: 0.940937 \tTraining Loss: 0.048788 \tValidation Loss: 0.037858 \n",
    "Epoch: 17 \tAccuracy: 0.920719 \tTraining Loss: 0.039500 \tValidation Loss: 0.057120 \n",
    "Epoch: 18 \tAccuracy: 0.929000 \tTraining Loss: 0.038879 \tValidation Loss: 0.048595 \n",
    "Epoch: 19 \tAccuracy: 0.941437 \tTraining Loss: 0.039195 \tValidation Loss: 0.037387 \n",
    "Epoch: 20 \tAccuracy: 0.938719 \tTraining Loss: 0.029895 \tValidation Loss: 0.043959 \n",
    "Epoch: 21 \tAccuracy: 0.941000 \tTraining Loss: 0.034057 \tValidation Loss: 0.043052 \n",
    "Epoch: 22 \tAccuracy: 0.944719 \tTraining Loss: 0.027338 \tValidation Loss: 0.039243 \n",
    "Epoch: 23 \tAccuracy: 0.940000 \tTraining Loss: 0.025532 \tValidation Loss: 0.045580 \n",
    "Epoch: 24 \tAccuracy: 0.948000 \tTraining Loss: 0.027400 \tValidation Loss: 0.037440 \n",
    "Epoch: 25 \tAccuracy: 0.937219 \tTraining Loss: 0.026083 \tValidation Loss: 0.043362 \n",
    "Final Results:\tAccuracy: 0.564633 \tTraining Loss: 0.033189 \tTesting Loss: 0.646926 \n",
    "\n",
    "\n",
    "Run 9\n",
    "\n",
    "epochs = 25\n",
    "val_percent = 0.2\n",
    "train_batch_size = 50\n",
    "test_batch_size = 50\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 25 \tBatch Size: 50\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.835622 \tTraining Loss: 0.314475 \tValidation Loss: 0.121267 \n",
    "Epoch: 2 \tAccuracy: 0.798622 \tTraining Loss: 0.123585 \tValidation Loss: 0.140467 \n",
    "Epoch: 3 \tAccuracy: 0.845622 \tTraining Loss: 0.115253 \tValidation Loss: 0.117120 \n",
    "Epoch: 4 \tAccuracy: 0.895061 \tTraining Loss: 0.098090 \tValidation Loss: 0.079591 \n",
    "Epoch: 5 \tAccuracy: 0.898951 \tTraining Loss: 0.077107 \tValidation Loss: 0.067475 \n",
    "Epoch: 6 \tAccuracy: 0.873341 \tTraining Loss: 0.078825 \tValidation Loss: 0.088468 \n",
    "Epoch: 7 \tAccuracy: 0.890061 \tTraining Loss: 0.070735 \tValidation Loss: 0.075376 \n",
    "Epoch: 8 \tAccuracy: 0.832232 \tTraining Loss: 0.070780 \tValidation Loss: 0.132952 \n",
    "Epoch: 9 \tAccuracy: 0.911390 \tTraining Loss: 0.068737 \tValidation Loss: 0.057574 \n",
    "Epoch: 10 \tAccuracy: 0.906890 \tTraining Loss: 0.041312 \tValidation Loss: 0.069724 \n",
    "Epoch: 11 \tAccuracy: 0.926561 \tTraining Loss: 0.047419 \tValidation Loss: 0.046882 \n",
    "Epoch: 12 \tAccuracy: 0.907561 \tTraining Loss: 0.033990 \tValidation Loss: 0.069589 \n",
    "Epoch: 13 \tAccuracy: 0.936780 \tTraining Loss: 0.036024 \tValidation Loss: 0.042515 \n",
    "Epoch: 14 \tAccuracy: 0.941780 \tTraining Loss: 0.029332 \tValidation Loss: 0.038811 \n",
    "Epoch: 15 \tAccuracy: 0.892671 \tTraining Loss: 0.037162 \tValidation Loss: 0.077334 \n",
    "Epoch: 16 \tAccuracy: 0.939671 \tTraining Loss: 0.027089 \tValidation Loss: 0.041924 \n",
    "Epoch: 17 \tAccuracy: 0.892171 \tTraining Loss: 0.028560 \tValidation Loss: 0.082107 \n",
    "Epoch: 18 \tAccuracy: 0.944280 \tTraining Loss: 0.033260 \tValidation Loss: 0.040751 \n",
    "Epoch: 19 \tAccuracy: 0.941171 \tTraining Loss: 0.026255 \tValidation Loss: 0.039314 \n",
    "Epoch: 20 \tAccuracy: 0.930561 \tTraining Loss: 0.018340 \tValidation Loss: 0.050456 \n",
    "Epoch: 21 \tAccuracy: 0.946561 \tTraining Loss: 0.020118 \tValidation Loss: 0.033873 \n",
    "Epoch: 22 \tAccuracy: 0.926451 \tTraining Loss: 0.021195 \tValidation Loss: 0.056718 \n",
    "Epoch: 23 \tAccuracy: 0.931280 \tTraining Loss: 0.017675 \tValidation Loss: 0.049975 \n",
    "Epoch: 24 \tAccuracy: 0.953890 \tTraining Loss: 0.024971 \tValidation Loss: 0.033525 \n",
    "Epoch: 25 \tAccuracy: 0.949500 \tTraining Loss: 0.014258 \tValidation Loss: 0.033003 \n",
    "Final Results:\tAccuracy: 0.598530 \tTraining Loss: 0.018827 \tTesting Loss: 0.526226 \n",
    "\n",
    "\n",
    "Run 10\n",
    "\n",
    "epochs = 50\n",
    "val_percent = 0.2\n",
    "train_batch_size = 10\n",
    "test_batch_size = 10\n",
    "eval_freq = 1\n",
    "\n",
    "criterion = nn.MultiMarginLoss(margin=1.0)\n",
    "\n",
    "Number of Epochs 50 \tBatch Size: 10\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.615500 \tTraining Loss: 0.404495 \tValidation Loss: 0.307876 \n",
    "Epoch: 2 \tAccuracy: 0.874000 \tTraining Loss: 0.204332 \tValidation Loss: 0.093994 \n",
    "Epoch: 3 \tAccuracy: 0.878500 \tTraining Loss: 0.163484 \tValidation Loss: 0.092706 \n",
    "Epoch: 4 \tAccuracy: 0.895500 \tTraining Loss: 0.155909 \tValidation Loss: 0.079284 \n",
    "Epoch: 5 \tAccuracy: 0.890000 \tTraining Loss: 0.135739 \tValidation Loss: 0.077842 \n",
    "Epoch: 6 \tAccuracy: 0.865000 \tTraining Loss: 0.136135 \tValidation Loss: 0.101431 \n",
    "Epoch: 7 \tAccuracy: 0.890000 \tTraining Loss: 0.123805 \tValidation Loss: 0.078219 \n",
    "Epoch: 8 \tAccuracy: 0.906500 \tTraining Loss: 0.111745 \tValidation Loss: 0.065994 \n",
    "Epoch: 9 \tAccuracy: 0.919500 \tTraining Loss: 0.110716 \tValidation Loss: 0.057569 \n",
    "Epoch: 10 \tAccuracy: 0.909500 \tTraining Loss: 0.100474 \tValidation Loss: 0.060372 \n",
    "Epoch: 11 \tAccuracy: 0.905000 \tTraining Loss: 0.105953 \tValidation Loss: 0.065719 \n",
    "Epoch: 12 \tAccuracy: 0.925500 \tTraining Loss: 0.096958 \tValidation Loss: 0.050604 \n",
    "Epoch: 13 \tAccuracy: 0.924500 \tTraining Loss: 0.088848 \tValidation Loss: 0.050439 \n",
    "Epoch: 14 \tAccuracy: 0.911000 \tTraining Loss: 0.082210 \tValidation Loss: 0.062055 \n",
    "Epoch: 15 \tAccuracy: 0.916500 \tTraining Loss: 0.088922 \tValidation Loss: 0.056016 \n",
    "Epoch: 16 \tAccuracy: 0.918500 \tTraining Loss: 0.083045 \tValidation Loss: 0.056962 \n",
    "Epoch: 17 \tAccuracy: 0.934500 \tTraining Loss: 0.076201 \tValidation Loss: 0.039789 \n",
    "Epoch: 18 \tAccuracy: 0.928000 \tTraining Loss: 0.077284 \tValidation Loss: 0.045058 \n",
    "Epoch: 19 \tAccuracy: 0.928500 \tTraining Loss: 0.064828 \tValidation Loss: 0.046921 \n",
    "Epoch: 20 \tAccuracy: 0.940000 \tTraining Loss: 0.069553 \tValidation Loss: 0.038839 \n",
    "Epoch: 21 \tAccuracy: 0.917000 \tTraining Loss: 0.061479 \tValidation Loss: 0.059879 \n",
    "Epoch: 22 \tAccuracy: 0.932500 \tTraining Loss: 0.061752 \tValidation Loss: 0.044464 \n",
    "Epoch: 23 \tAccuracy: 0.932500 \tTraining Loss: 0.067148 \tValidation Loss: 0.042130 \n",
    "Epoch: 24 \tAccuracy: 0.887500 \tTraining Loss: 0.061522 \tValidation Loss: 0.069228 \n",
    "Epoch: 25 \tAccuracy: 0.923000 \tTraining Loss: 0.061900 \tValidation Loss: 0.054122 \n",
    "Epoch: 26 \tAccuracy: 0.929500 \tTraining Loss: 0.058621 \tValidation Loss: 0.045503 \n",
    "Epoch: 27 \tAccuracy: 0.940000 \tTraining Loss: 0.054892 \tValidation Loss: 0.042663 \n",
    "Epoch: 28 \tAccuracy: 0.938000 \tTraining Loss: 0.057282 \tValidation Loss: 0.044770 \n",
    "Epoch: 29 \tAccuracy: 0.945500 \tTraining Loss: 0.056124 \tValidation Loss: 0.032680 \n",
    "Epoch: 30 \tAccuracy: 0.935500 \tTraining Loss: 0.059049 \tValidation Loss: 0.043736 \n",
    "Epoch: 31 \tAccuracy: 0.934000 \tTraining Loss: 0.050999 \tValidation Loss: 0.039267 \n",
    "Epoch: 32 \tAccuracy: 0.949000 \tTraining Loss: 0.050659 \tValidation Loss: 0.032414 \n",
    "Epoch: 33 \tAccuracy: 0.942500 \tTraining Loss: 0.052174 \tValidation Loss: 0.034932 \n",
    "Epoch: 34 \tAccuracy: 0.945500 \tTraining Loss: 0.045395 \tValidation Loss: 0.034944 \n",
    "Epoch: 35 \tAccuracy: 0.954000 \tTraining Loss: 0.049651 \tValidation Loss: 0.031507 \n",
    "Epoch: 36 \tAccuracy: 0.945000 \tTraining Loss: 0.046211 \tValidation Loss: 0.032411 \n",
    "Epoch: 37 \tAccuracy: 0.942000 \tTraining Loss: 0.045516 \tValidation Loss: 0.037230 \n",
    "Epoch: 38 \tAccuracy: 0.943000 \tTraining Loss: 0.049098 \tValidation Loss: 0.036136 \n",
    "Epoch: 39 \tAccuracy: 0.946500 \tTraining Loss: 0.046263 \tValidation Loss: 0.030937 \n",
    "Epoch: 40 \tAccuracy: 0.953500 \tTraining Loss: 0.043737 \tValidation Loss: 0.028537 \n",
    "Epoch: 41 \tAccuracy: 0.953500 \tTraining Loss: 0.044831 \tValidation Loss: 0.029608 \n",
    "Epoch: 42 \tAccuracy: 0.947000 \tTraining Loss: 0.044573 \tValidation Loss: 0.032519 \n",
    "Epoch: 43 \tAccuracy: 0.939500 \tTraining Loss: 0.039212 \tValidation Loss: 0.036444 \n",
    "Epoch: 44 \tAccuracy: 0.952500 \tTraining Loss: 0.042255 \tValidation Loss: 0.029741 \n",
    "Epoch: 45 \tAccuracy: 0.950500 \tTraining Loss: 0.038227 \tValidation Loss: 0.031813 \n",
    "Epoch: 46 \tAccuracy: 0.957000 \tTraining Loss: 0.044166 \tValidation Loss: 0.027725 \n",
    "Epoch: 47 \tAccuracy: 0.943500 \tTraining Loss: 0.034964 \tValidation Loss: 0.037995 \n",
    "Epoch: 48 \tAccuracy: 0.933500 \tTraining Loss: 0.034849 \tValidation Loss: 0.047254 \n",
    "Epoch: 49 \tAccuracy: 0.956000 \tTraining Loss: 0.039633 \tValidation Loss: 0.029550 \n",
    "Epoch: 50 \tAccuracy: 0.960500 \tTraining Loss: 0.036304 \tValidation Loss: 0.025657 \n",
    "Final Results:\tAccuracy: 0.551520 \tTraining Loss: 0.044299 \tTesting Loss: 0.742072\n",
    "\n",
    "\n",
    "Epoch: 9 \tAccuracy: 0.861219 \tTraining Loss: 0.247204 \tValidation Loss: 0.344762 \n",
    "Epoch: 10 \tAccuracy: 0.906219 \tTraining Loss: 0.226018 \tValidation Loss: 0.245339 \n",
    "Final Results:\tAccuracy: 0.632933 \tTraining Loss: 0.231431 \tTesting Loss: 1.212736 \n",
    "\n",
    "\n",
    "Run 11\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 10 \tBatch Size: 50 \tValidation Percent: 0.2\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.690293 \tTraining Loss: 0.804683 \tValidation Loss: 0.667131 \n",
    "Epoch: 2 \tAccuracy: 0.740683 \tTraining Loss: 0.486185 \tValidation Loss: 0.599333 \n",
    "Epoch: 3 \tAccuracy: 0.900061 \tTraining Loss: 0.365753 \tValidation Loss: 0.272520 \n",
    "Epoch: 4 \tAccuracy: 0.849232 \tTraining Loss: 0.336812 \tValidation Loss: 0.401255 \n",
    "Epoch: 5 \tAccuracy: 0.901561 \tTraining Loss: 0.302169 \tValidation Loss: 0.263551 \n",
    "Epoch: 6 \tAccuracy: 0.916622 \tTraining Loss: 0.225439 \tValidation Loss: 0.210753 \n",
    "Epoch: 7 \tAccuracy: 0.926671 \tTraining Loss: 0.256873 \tValidation Loss: 0.207533 \n",
    "Epoch: 8 \tAccuracy: 0.912451 \tTraining Loss: 0.197932 \tValidation Loss: 0.207827 \n",
    "Epoch: 9 \tAccuracy: 0.904171 \tTraining Loss: 0.193991 \tValidation Loss: 0.225530 \n",
    "Epoch: 10 \tAccuracy: 0.939171 \tTraining Loss: 0.164434 \tValidation Loss: 0.152744 \n",
    "Final Results:\tAccuracy: 0.637492 \tTraining Loss: 0.158227 \tTesting Loss: 1.406197 \n",
    "\n",
    "\n",
    "Run 12\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 25 \tBatch Size: 10 \tValidation Percent: 0.2\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.770500 \tTraining Loss: 0.967307 \tValidation Loss: 0.529906 \n",
    "Epoch: 2 \tAccuracy: 0.829500 \tTraining Loss: 0.609563 \tValidation Loss: 0.429458 \n",
    "Epoch: 3 \tAccuracy: 0.879000 \tTraining Loss: 0.519460 \tValidation Loss: 0.316326 \n",
    "Epoch: 4 \tAccuracy: 0.881000 \tTraining Loss: 0.500834 \tValidation Loss: 0.328851 \n",
    "Epoch: 5 \tAccuracy: 0.842000 \tTraining Loss: 0.441789 \tValidation Loss: 0.395934 \n",
    "Epoch: 6 \tAccuracy: 0.894000 \tTraining Loss: 0.424043 \tValidation Loss: 0.284087 \n",
    "Epoch: 7 \tAccuracy: 0.898500 \tTraining Loss: 0.408934 \tValidation Loss: 0.250132 \n",
    "Epoch: 8 \tAccuracy: 0.889500 \tTraining Loss: 0.386012 \tValidation Loss: 0.282248 \n",
    "Epoch: 9 \tAccuracy: 0.897500 \tTraining Loss: 0.383355 \tValidation Loss: 0.267759 \n",
    "Epoch: 10 \tAccuracy: 0.869500 \tTraining Loss: 0.367704 \tValidation Loss: 0.329774 \n",
    "Epoch: 11 \tAccuracy: 0.905500 \tTraining Loss: 0.340193 \tValidation Loss: 0.225654 \n",
    "Epoch: 12 \tAccuracy: 0.913000 \tTraining Loss: 0.338871 \tValidation Loss: 0.216025 \n",
    "Epoch: 13 \tAccuracy: 0.914000 \tTraining Loss: 0.302225 \tValidation Loss: 0.209095 \n",
    "Epoch: 14 \tAccuracy: 0.917000 \tTraining Loss: 0.320214 \tValidation Loss: 0.216257 \n",
    "Epoch: 15 \tAccuracy: 0.931000 \tTraining Loss: 0.303105 \tValidation Loss: 0.190666 \n",
    "Epoch: 16 \tAccuracy: 0.920500 \tTraining Loss: 0.279768 \tValidation Loss: 0.205784 \n",
    "Epoch: 17 \tAccuracy: 0.916000 \tTraining Loss: 0.285511 \tValidation Loss: 0.199706 \n",
    "Epoch: 18 \tAccuracy: 0.919500 \tTraining Loss: 0.269161 \tValidation Loss: 0.209342 \n",
    "Epoch: 19 \tAccuracy: 0.930500 \tTraining Loss: 0.246930 \tValidation Loss: 0.169357 \n",
    "Epoch: 20 \tAccuracy: 0.925000 \tTraining Loss: 0.260977 \tValidation Loss: 0.191430 \n",
    "Epoch: 21 \tAccuracy: 0.928500 \tTraining Loss: 0.237586 \tValidation Loss: 0.184785 \n",
    "Epoch: 22 \tAccuracy: 0.928500 \tTraining Loss: 0.225773 \tValidation Loss: 0.182169 \n",
    "Epoch: 23 \tAccuracy: 0.944000 \tTraining Loss: 0.216880 \tValidation Loss: 0.155428 \n",
    "Epoch: 24 \tAccuracy: 0.930500 \tTraining Loss: 0.231981 \tValidation Loss: 0.177724 \n",
    "Epoch: 25 \tAccuracy: 0.932000 \tTraining Loss: 0.207603 \tValidation Loss: 0.189195 \n",
    "Final Results:\tAccuracy: 0.572060 \tTraining Loss: 0.223838 \tTesting Loss: 1.784645 \n",
    "\n",
    "\n",
    "Run 13\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 25 \tBatch Size: 25 \tValidation Percent: 0.2\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.830219 \tTraining Loss: 0.855608 \tValidation Loss: 0.479221 \n",
    "Epoch: 2 \tAccuracy: 0.880875 \tTraining Loss: 0.498373 \tValidation Loss: 0.304472 \n",
    "Epoch: 3 \tAccuracy: 0.832438 \tTraining Loss: 0.419475 \tValidation Loss: 0.399047 \n",
    "Epoch: 4 \tAccuracy: 0.902500 \tTraining Loss: 0.380038 \tValidation Loss: 0.242820 \n",
    "Epoch: 5 \tAccuracy: 0.912500 \tTraining Loss: 0.299875 \tValidation Loss: 0.216459 \n",
    "Epoch: 6 \tAccuracy: 0.865437 \tTraining Loss: 0.275850 \tValidation Loss: 0.311658 \n",
    "Epoch: 7 \tAccuracy: 0.908094 \tTraining Loss: 0.251369 \tValidation Loss: 0.239543 \n",
    "Epoch: 8 \tAccuracy: 0.909719 \tTraining Loss: 0.237252 \tValidation Loss: 0.226684 \n",
    "Epoch: 9 \tAccuracy: 0.930219 \tTraining Loss: 0.235727 \tValidation Loss: 0.188232 \n",
    "Epoch: 10 \tAccuracy: 0.910719 \tTraining Loss: 0.213302 \tValidation Loss: 0.220882 \n",
    "Epoch: 11 \tAccuracy: 0.894156 \tTraining Loss: 0.194377 \tValidation Loss: 0.280342 \n",
    "Epoch: 12 \tAccuracy: 0.941219 \tTraining Loss: 0.178332 \tValidation Loss: 0.155061 \n",
    "Epoch: 13 \tAccuracy: 0.929219 \tTraining Loss: 0.166174 \tValidation Loss: 0.189644 \n",
    "Epoch: 14 \tAccuracy: 0.931719 \tTraining Loss: 0.167197 \tValidation Loss: 0.183463 \n",
    "Epoch: 15 \tAccuracy: 0.929937 \tTraining Loss: 0.156146 \tValidation Loss: 0.185055 \n",
    "Epoch: 16 \tAccuracy: 0.950000 \tTraining Loss: 0.128333 \tValidation Loss: 0.127784 \n",
    "Epoch: 17 \tAccuracy: 0.960000 \tTraining Loss: 0.098709 \tValidation Loss: 0.110066 \n",
    "Epoch: 18 \tAccuracy: 0.936000 \tTraining Loss: 0.097933 \tValidation Loss: 0.185667 \n",
    "Epoch: 19 \tAccuracy: 0.912219 \tTraining Loss: 0.132238 \tValidation Loss: 0.256992 \n",
    "Epoch: 20 \tAccuracy: 0.956500 \tTraining Loss: 0.104629 \tValidation Loss: 0.125040 \n",
    "Epoch: 21 \tAccuracy: 0.922500 \tTraining Loss: 0.086785 \tValidation Loss: 0.228874 \n",
    "Epoch: 22 \tAccuracy: 0.935000 \tTraining Loss: 0.102344 \tValidation Loss: 0.201008 \n",
    "Epoch: 23 \tAccuracy: 0.946000 \tTraining Loss: 0.115013 \tValidation Loss: 0.144343 \n",
    "Epoch: 24 \tAccuracy: 0.956500 \tTraining Loss: 0.105293 \tValidation Loss: 0.116717 \n",
    "Epoch: 25 \tAccuracy: 0.966000 \tTraining Loss: 0.069673 \tValidation Loss: 0.101058 \n",
    "Final Results:\tAccuracy: 0.569433 \tTraining Loss: 0.110016 \tTesting Loss: 2.139700 \n",
    "\n",
    "\n",
    "Run 14\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 25 \tBatch Size: 50 \tValidation Percent: 0.2\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.787963 \tTraining Loss: 0.897462 \tValidation Loss: 0.504292 \n",
    "Epoch: 2 \tAccuracy: 0.807232 \tTraining Loss: 0.491968 \tValidation Loss: 0.464330 \n",
    "Epoch: 3 \tAccuracy: 0.862122 \tTraining Loss: 0.408096 \tValidation Loss: 0.328883 \n",
    "Epoch: 4 \tAccuracy: 0.860841 \tTraining Loss: 0.369210 \tValidation Loss: 0.322186 \n",
    "Epoch: 5 \tAccuracy: 0.874951 \tTraining Loss: 0.321590 \tValidation Loss: 0.326853 \n",
    "Epoch: 6 \tAccuracy: 0.911390 \tTraining Loss: 0.266932 \tValidation Loss: 0.213909 \n",
    "Epoch: 7 \tAccuracy: 0.914732 \tTraining Loss: 0.237886 \tValidation Loss: 0.209115 \n",
    "Epoch: 8 \tAccuracy: 0.908780 \tTraining Loss: 0.207232 \tValidation Loss: 0.219961 \n",
    "Epoch: 9 \tAccuracy: 0.904171 \tTraining Loss: 0.198630 \tValidation Loss: 0.229252 \n",
    "Epoch: 10 \tAccuracy: 0.925451 \tTraining Loss: 0.185391 \tValidation Loss: 0.185033 \n",
    "Epoch: 11 \tAccuracy: 0.911561 \tTraining Loss: 0.177937 \tValidation Loss: 0.226930 \n",
    "Epoch: 12 \tAccuracy: 0.935061 \tTraining Loss: 0.167364 \tValidation Loss: 0.160697 \n",
    "Epoch: 13 \tAccuracy: 0.918390 \tTraining Loss: 0.156361 \tValidation Loss: 0.215037 \n",
    "Epoch: 14 \tAccuracy: 0.835780 \tTraining Loss: 0.168844 \tValidation Loss: 0.478164 \n",
    "Epoch: 15 \tAccuracy: 0.927061 \tTraining Loss: 0.160437 \tValidation Loss: 0.178430 \n",
    "Epoch: 16 \tAccuracy: 0.937671 \tTraining Loss: 0.134645 \tValidation Loss: 0.155506 \n",
    "Epoch: 17 \tAccuracy: 0.951890 \tTraining Loss: 0.078699 \tValidation Loss: 0.136037 \n",
    "Epoch: 18 \tAccuracy: 0.913451 \tTraining Loss: 0.099872 \tValidation Loss: 0.259239 \n",
    "Epoch: 19 \tAccuracy: 0.953890 \tTraining Loss: 0.100969 \tValidation Loss: 0.113383 \n",
    "Epoch: 20 \tAccuracy: 0.953671 \tTraining Loss: 0.113627 \tValidation Loss: 0.128499 \n",
    "Epoch: 21 \tAccuracy: 0.927280 \tTraining Loss: 0.068995 \tValidation Loss: 0.203522 \n",
    "Epoch: 22 \tAccuracy: 0.959280 \tTraining Loss: 0.060184 \tValidation Loss: 0.103099 \n",
    "Epoch: 23 \tAccuracy: 0.918890 \tTraining Loss: 0.060864 \tValidation Loss: 0.217166 \n",
    "Epoch: 24 \tAccuracy: 0.954500 \tTraining Loss: 0.059701 \tValidation Loss: 0.131899 \n",
    "Epoch: 25 \tAccuracy: 0.970500 \tTraining Loss: 0.043710 \tValidation Loss: 0.092661 \n",
    "Final Results:\tAccuracy: 0.603589 \tTraining Loss: 0.092907 \tTesting Loss: 1.944045 \n",
    "\n",
    "\n",
    "Run 15\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 50 \tBatch Size: 10 \tValidation Percent: 0.2\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.773500 \tTraining Loss: 0.970494 \tValidation Loss: 0.572447 \n",
    "Epoch: 2 \tAccuracy: 0.838000 \tTraining Loss: 0.606431 \tValidation Loss: 0.453523 \n",
    "Epoch: 3 \tAccuracy: 0.867000 \tTraining Loss: 0.492486 \tValidation Loss: 0.340771 \n",
    "Epoch: 4 \tAccuracy: 0.871500 \tTraining Loss: 0.495966 \tValidation Loss: 0.336861 \n",
    "Epoch: 5 \tAccuracy: 0.891000 \tTraining Loss: 0.453057 \tValidation Loss: 0.290129 \n",
    "Epoch: 6 \tAccuracy: 0.885000 \tTraining Loss: 0.410669 \tValidation Loss: 0.292836 \n",
    "Epoch: 7 \tAccuracy: 0.889500 \tTraining Loss: 0.400224 \tValidation Loss: 0.284332 \n",
    "Epoch: 8 \tAccuracy: 0.835500 \tTraining Loss: 0.382221 \tValidation Loss: 0.379654 \n",
    "Epoch: 9 \tAccuracy: 0.908000 \tTraining Loss: 0.343570 \tValidation Loss: 0.245482 \n",
    "Epoch: 10 \tAccuracy: 0.878500 \tTraining Loss: 0.334101 \tValidation Loss: 0.316069 \n",
    "Epoch: 11 \tAccuracy: 0.919500 \tTraining Loss: 0.323566 \tValidation Loss: 0.214422 \n",
    "Epoch: 12 \tAccuracy: 0.911500 \tTraining Loss: 0.303907 \tValidation Loss: 0.225689 \n",
    "Epoch: 13 \tAccuracy: 0.927500 \tTraining Loss: 0.278901 \tValidation Loss: 0.194093 \n",
    "Epoch: 14 \tAccuracy: 0.920000 \tTraining Loss: 0.276590 \tValidation Loss: 0.209097 \n",
    "Epoch: 15 \tAccuracy: 0.937000 \tTraining Loss: 0.277939 \tValidation Loss: 0.177061 \n",
    "Epoch: 16 \tAccuracy: 0.904500 \tTraining Loss: 0.259435 \tValidation Loss: 0.236691 \n",
    "Epoch: 17 \tAccuracy: 0.942500 \tTraining Loss: 0.260195 \tValidation Loss: 0.151711 \n",
    "Epoch: 18 \tAccuracy: 0.920500 \tTraining Loss: 0.238594 \tValidation Loss: 0.188101 \n",
    "Epoch: 19 \tAccuracy: 0.946000 \tTraining Loss: 0.212026 \tValidation Loss: 0.147180 \n",
    "Epoch: 20 \tAccuracy: 0.933000 \tTraining Loss: 0.209602 \tValidation Loss: 0.160090 \n",
    "Epoch: 21 \tAccuracy: 0.917500 \tTraining Loss: 0.201314 \tValidation Loss: 0.201122 \n",
    "Epoch: 22 \tAccuracy: 0.948500 \tTraining Loss: 0.212906 \tValidation Loss: 0.135884 \n",
    "Epoch: 23 \tAccuracy: 0.923000 \tTraining Loss: 0.191234 \tValidation Loss: 0.187037 \n",
    "Epoch: 24 \tAccuracy: 0.928000 \tTraining Loss: 0.181849 \tValidation Loss: 0.188662 \n",
    "Epoch: 25 \tAccuracy: 0.937500 \tTraining Loss: 0.181295 \tValidation Loss: 0.145349 \n",
    "Epoch: 26 \tAccuracy: 0.935500 \tTraining Loss: 0.173408 \tValidation Loss: 0.162939 \n",
    "Epoch: 27 \tAccuracy: 0.945000 \tTraining Loss: 0.172051 \tValidation Loss: 0.148137 \n",
    "Epoch: 28 \tAccuracy: 0.958500 \tTraining Loss: 0.149575 \tValidation Loss: 0.116008 \n",
    "Epoch: 29 \tAccuracy: 0.945500 \tTraining Loss: 0.156936 \tValidation Loss: 0.138169 \n",
    "Epoch: 30 \tAccuracy: 0.948000 \tTraining Loss: 0.167449 \tValidation Loss: 0.137033 \n",
    "Epoch: 31 \tAccuracy: 0.951000 \tTraining Loss: 0.153111 \tValidation Loss: 0.132454 \n",
    "Epoch: 32 \tAccuracy: 0.948500 \tTraining Loss: 0.151057 \tValidation Loss: 0.144834 \n",
    "Epoch: 33 \tAccuracy: 0.942500 \tTraining Loss: 0.142528 \tValidation Loss: 0.170770 \n",
    "Epoch: 34 \tAccuracy: 0.957500 \tTraining Loss: 0.139631 \tValidation Loss: 0.109953 \n",
    "Epoch: 35 \tAccuracy: 0.944500 \tTraining Loss: 0.146168 \tValidation Loss: 0.158937 \n",
    "Epoch: 36 \tAccuracy: 0.949000 \tTraining Loss: 0.154020 \tValidation Loss: 0.133839 \n",
    "Epoch: 37 \tAccuracy: 0.930500 \tTraining Loss: 0.141423 \tValidation Loss: 0.200024 \n",
    "Epoch: 38 \tAccuracy: 0.952000 \tTraining Loss: 0.127552 \tValidation Loss: 0.113707 \n",
    "Epoch: 39 \tAccuracy: 0.949000 \tTraining Loss: 0.135605 \tValidation Loss: 0.145724 \n",
    "Epoch: 40 \tAccuracy: 0.963000 \tTraining Loss: 0.128991 \tValidation Loss: 0.112127 \n",
    "Epoch: 41 \tAccuracy: 0.957000 \tTraining Loss: 0.129072 \tValidation Loss: 0.104938 \n",
    "Epoch: 42 \tAccuracy: 0.965500 \tTraining Loss: 0.120065 \tValidation Loss: 0.093580 \n",
    "Epoch: 43 \tAccuracy: 0.958500 \tTraining Loss: 0.134817 \tValidation Loss: 0.111286 \n",
    "Epoch: 44 \tAccuracy: 0.963500 \tTraining Loss: 0.109546 \tValidation Loss: 0.102473 \n",
    "Epoch: 45 \tAccuracy: 0.969500 \tTraining Loss: 0.113328 \tValidation Loss: 0.080936 \n",
    "Epoch: 46 \tAccuracy: 0.969000 \tTraining Loss: 0.125886 \tValidation Loss: 0.090551 \n",
    "Epoch: 47 \tAccuracy: 0.944000 \tTraining Loss: 0.107990 \tValidation Loss: 0.150715 \n",
    "Epoch: 48 \tAccuracy: 0.950000 \tTraining Loss: 0.110817 \tValidation Loss: 0.163217 \n",
    "Epoch: 49 \tAccuracy: 0.948500 \tTraining Loss: 0.103674 \tValidation Loss: 0.164590 \n",
    "Epoch: 50 \tAccuracy: 0.954000 \tTraining Loss: 0.114963 \tValidation Loss: 0.121440 \n",
    "Final Results:\tAccuracy: 0.553701 \tTraining Loss: 0.137106 \tTesting Loss: 2.250852 \n",
    "\n",
    "\n",
    "Run 16\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 50 \tBatch Size: 25 \tValidation Percent: 0.2\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Epoch: 1 \tAccuracy: 0.799000 \tTraining Loss: 0.907682 \tValidation Loss: 0.495177 \n",
    "Epoch: 2 \tAccuracy: 0.759656 \tTraining Loss: 0.512498 \tValidation Loss: 0.597180 \n",
    "Epoch: 3 \tAccuracy: 0.884094 \tTraining Loss: 0.434474 \tValidation Loss: 0.302490 \n",
    "Epoch: 4 \tAccuracy: 0.867156 \tTraining Loss: 0.369367 \tValidation Loss: 0.345526 \n",
    "Epoch: 5 \tAccuracy: 0.859656 \tTraining Loss: 0.315009 \tValidation Loss: 0.373451 \n",
    "Epoch: 6 \tAccuracy: 0.892500 \tTraining Loss: 0.307191 \tValidation Loss: 0.285387 \n",
    "Epoch: 7 \tAccuracy: 0.912437 \tTraining Loss: 0.260716 \tValidation Loss: 0.220679 \n",
    "Epoch: 8 \tAccuracy: 0.912719 \tTraining Loss: 0.248557 \tValidation Loss: 0.213298 \n",
    "Epoch: 9 \tAccuracy: 0.855375 \tTraining Loss: 0.232020 \tValidation Loss: 0.379515 \n",
    "Epoch: 10 \tAccuracy: 0.901656 \tTraining Loss: 0.216162 \tValidation Loss: 0.264605 \n",
    "Epoch: 11 \tAccuracy: 0.915500 \tTraining Loss: 0.179599 \tValidation Loss: 0.208280 \n",
    "Epoch: 12 \tAccuracy: 0.904500 \tTraining Loss: 0.194271 \tValidation Loss: 0.257396 \n",
    "Epoch: 13 \tAccuracy: 0.930937 \tTraining Loss: 0.172158 \tValidation Loss: 0.190657 \n",
    "Epoch: 14 \tAccuracy: 0.890500 \tTraining Loss: 0.150538 \tValidation Loss: 0.318943 \n",
    "Epoch: 15 \tAccuracy: 0.852156 \tTraining Loss: 0.143470 \tValidation Loss: 0.483747 \n",
    "Epoch: 16 \tAccuracy: 0.928719 \tTraining Loss: 0.154058 \tValidation Loss: 0.205602 \n",
    "Epoch: 17 \tAccuracy: 0.935500 \tTraining Loss: 0.124643 \tValidation Loss: 0.170732 \n",
    "Epoch: 18 \tAccuracy: 0.951500 \tTraining Loss: 0.131361 \tValidation Loss: 0.134944 \n",
    "Epoch: 19 \tAccuracy: 0.942719 \tTraining Loss: 0.114394 \tValidation Loss: 0.151227 \n",
    "Epoch: 20 \tAccuracy: 0.952437 \tTraining Loss: 0.128288 \tValidation Loss: 0.129949 \n",
    "Epoch: 21 \tAccuracy: 0.946719 \tTraining Loss: 0.112846 \tValidation Loss: 0.139828 \n",
    "Epoch: 22 \tAccuracy: 0.954437 \tTraining Loss: 0.099770 \tValidation Loss: 0.122431 \n",
    "Epoch: 23 \tAccuracy: 0.951719 \tTraining Loss: 0.079102 \tValidation Loss: 0.158471 \n",
    "Epoch: 24 \tAccuracy: 0.940500 \tTraining Loss: 0.086558 \tValidation Loss: 0.195820 \n",
    "Epoch: 25 \tAccuracy: 0.953719 \tTraining Loss: 0.078458 \tValidation Loss: 0.134334 \n",
    "Epoch: 26 \tAccuracy: 0.955000 \tTraining Loss: 0.074199 \tValidation Loss: 0.121177 \n",
    "Epoch: 27 \tAccuracy: 0.929000 \tTraining Loss: 0.074563 \tValidation Loss: 0.217670 \n",
    "Epoch: 28 \tAccuracy: 0.960000 \tTraining Loss: 0.065661 \tValidation Loss: 0.122243 \n",
    "Epoch: 29 \tAccuracy: 0.955719 \tTraining Loss: 0.075949 \tValidation Loss: 0.120383 \n",
    "Epoch: 30 \tAccuracy: 0.950000 \tTraining Loss: 0.084585 \tValidation Loss: 0.122354 \n",
    "Epoch: 31 \tAccuracy: 0.960500 \tTraining Loss: 0.069211 \tValidation Loss: 0.119626 \n",
    "Epoch: 32 \tAccuracy: 0.952437 \tTraining Loss: 0.076621 \tValidation Loss: 0.124157 \n",
    "Epoch: 33 \tAccuracy: 0.967500 \tTraining Loss: 0.062922 \tValidation Loss: 0.085132 \n",
    "Epoch: 34 \tAccuracy: 0.958719 \tTraining Loss: 0.057059 \tValidation Loss: 0.124251 \n",
    "Epoch: 35 \tAccuracy: 0.957219 \tTraining Loss: 0.073105 \tValidation Loss: 0.132729 \n",
    "Epoch: 36 \tAccuracy: 0.958500 \tTraining Loss: 0.051005 \tValidation Loss: 0.117122 \n",
    "Epoch: 37 \tAccuracy: 0.959000 \tTraining Loss: 0.059805 \tValidation Loss: 0.138598 \n",
    "Epoch: 38 \tAccuracy: 0.962219 \tTraining Loss: 0.058748 \tValidation Loss: 0.108313 \n",
    "Epoch: 39 \tAccuracy: 0.954000 \tTraining Loss: 0.053703 \tValidation Loss: 0.127600 \n",
    "Epoch: 40 \tAccuracy: 0.957719 \tTraining Loss: 0.074303 \tValidation Loss: 0.120411 \n",
    "Epoch: 41 \tAccuracy: 0.966719 \tTraining Loss: 0.054813 \tValidation Loss: 0.097321 \n",
    "Epoch: 42 \tAccuracy: 0.968500 \tTraining Loss: 0.047670 \tValidation Loss: 0.082359 \n",
    "Epoch: 43 \tAccuracy: 0.966500 \tTraining Loss: 0.054459 \tValidation Loss: 0.100934 \n",
    "Epoch: 44 \tAccuracy: 0.968156 \tTraining Loss: 0.052016 \tValidation Loss: 0.096830 \n",
    "Epoch: 45 \tAccuracy: 0.941000 \tTraining Loss: 0.049038 \tValidation Loss: 0.180916 \n",
    "Epoch: 46 \tAccuracy: 0.958656 \tTraining Loss: 0.055619 \tValidation Loss: 0.122170 \n",
    "Epoch: 47 \tAccuracy: 0.966000 \tTraining Loss: 0.031796 \tValidation Loss: 0.109764 \n",
    "Epoch: 48 \tAccuracy: 0.961500 \tTraining Loss: 0.048712 \tValidation Loss: 0.122513 \n",
    "Epoch: 49 \tAccuracy: 0.964219 \tTraining Loss: 0.050489 \tValidation Loss: 0.132052 \n",
    "Epoch: 50 \tAccuracy: 0.964719 \tTraining Loss: 0.049733 \tValidation Loss: 0.097888 \n",
    "Final Results:\tAccuracy: 0.578233 \tTraining Loss: 0.065914 \tTesting Loss: 1.952858 \n",
    "\n",
    "\n",
    "Run 17\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 10 \tBatch Size: 50 \tValidation Percent: 0.2\n",
    "Images resized to 30x40px.\n",
    "Beginning setup...\n",
    "Setting up train, test, and validation sets...\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Beginning training...\n",
    "Epoch: 1 \tAccuracy: 0.600415 \tTraining Loss: 1.097977 \tValidation Loss: 1.160111 \n",
    "Epoch: 2 \tAccuracy: 0.615024 \tTraining Loss: 0.916336 \tValidation Loss: 1.170981 \n",
    "Epoch: 3 \tAccuracy: 0.659744 \tTraining Loss: 0.853748 \tValidation Loss: 1.069735 \n",
    "Epoch: 4 \tAccuracy: 0.612244 \tTraining Loss: 0.811477 \tValidation Loss: 1.334290 \n",
    "Epoch: 5 \tAccuracy: 0.677024 \tTraining Loss: 0.761510 \tValidation Loss: 0.830155 \n",
    "Epoch: 6 \tAccuracy: 0.678963 \tTraining Loss: 0.710578 \tValidation Loss: 0.892294 \n",
    "Epoch: 7 \tAccuracy: 0.675573 \tTraining Loss: 0.671650 \tValidation Loss: 0.891510 \n",
    "Epoch: 8 \tAccuracy: 0.683963 \tTraining Loss: 0.611281 \tValidation Loss: 0.838476 \n",
    "Epoch: 9 \tAccuracy: 0.679354 \tTraining Loss: 0.581496 \tValidation Loss: 0.808214 \n",
    "Epoch: 10 \tAccuracy: 0.690573 \tTraining Loss: 0.547951 \tValidation Loss: 1.292905 \n",
    "Final Results:\tAccuracy: 0.488930 \tTraining Loss: 0.588135 \tTesting Loss: 1.627002 \n",
    "\n",
    "\n",
    "Run 18\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 10 \tBatch Size: 100 \tValidation Percent: 0.2\n",
    "Images resized to 30x40px.\n",
    "Beginning setup...\n",
    "Setting up train, test, and validation sets...\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Beginning training...\n",
    "Epoch: 1 \tAccuracy: 0.555176 \tTraining Loss: 1.124714 \tValidation Loss: 1.049849 \n",
    "Epoch: 2 \tAccuracy: 0.645368 \tTraining Loss: 0.877542 \tValidation Loss: 0.900281 \n",
    "Epoch: 3 \tAccuracy: 0.631522 \tTraining Loss: 0.824654 \tValidation Loss: 0.868768 \n",
    "Epoch: 4 \tAccuracy: 0.667016 \tTraining Loss: 0.748276 \tValidation Loss: 0.851706 \n",
    "Epoch: 5 \tAccuracy: 0.682368 \tTraining Loss: 0.693535 \tValidation Loss: 0.783253 \n",
    "Epoch: 6 \tAccuracy: 0.681868 \tTraining Loss: 0.632877 \tValidation Loss: 0.782845 \n",
    "Epoch: 7 \tAccuracy: 0.683863 \tTraining Loss: 0.577922 \tValidation Loss: 0.807150 \n",
    "Epoch: 8 \tAccuracy: 0.711665 \tTraining Loss: 0.521608 \tValidation Loss: 0.736940 \n",
    "Epoch: 9 \tAccuracy: 0.707764 \tTraining Loss: 0.454957 \tValidation Loss: 0.785636 \n",
    "Epoch: 10 \tAccuracy: 0.719610 \tTraining Loss: 0.407335 \tValidation Loss: 0.788728 \n",
    "Final Results:\tAccuracy: 0.479269 \tTraining Loss: 0.450259 \tTesting Loss: 1.560974 \n",
    "\n",
    "\n",
    "Run 19\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 10 \tBatch Size: 200 \tValidation Percent: 0.2\n",
    "Images resized to 30x40px.\n",
    "Beginning setup...\n",
    "Setting up train, test, and validation sets...\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Beginning training...\n",
    "Epoch: 1 \tAccuracy: 0.599804 \tTraining Loss: 1.171397 \tValidation Loss: 0.973513 \n",
    "Epoch: 2 \tAccuracy: 0.588874 \tTraining Loss: 0.937229 \tValidation Loss: 1.015982 \n",
    "Epoch: 3 \tAccuracy: 0.612280 \tTraining Loss: 0.814486 \tValidation Loss: 0.986740 \n",
    "Epoch: 4 \tAccuracy: 0.636063 \tTraining Loss: 0.740062 \tValidation Loss: 0.893427 \n",
    "Epoch: 5 \tAccuracy: 0.672327 \tTraining Loss: 0.669452 \tValidation Loss: 0.819181 \n",
    "Epoch: 6 \tAccuracy: 0.674398 \tTraining Loss: 0.575852 \tValidation Loss: 0.836685 \n",
    "Epoch: 7 \tAccuracy: 0.697681 \tTraining Loss: 0.508199 \tValidation Loss: 0.825571 \n",
    "Epoch: 8 \tAccuracy: 0.668016 \tTraining Loss: 0.431571 \tValidation Loss: 0.863401 \n",
    "Epoch: 9 \tAccuracy: 0.695110 \tTraining Loss: 0.375060 \tValidation Loss: 0.817083 \n",
    "Epoch: 10 \tAccuracy: 0.676657 \tTraining Loss: 0.315847 \tValidation Loss: 0.896484 \n",
    "Final Results:\tAccuracy: 0.483174 \tTraining Loss: 0.388844 \tTesting Loss: 1.670899 \n",
    "\n",
    "\n",
    "Run 20\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 10 \tBatch Size: 400 \tValidation Percent: 0.2\n",
    "Images resized to 30x40px.\n",
    "Beginning setup...\n",
    "Setting up train, test, and validation sets...\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Beginning training...\n",
    "Epoch: 1 \tAccuracy: 0.587986 \tTraining Loss: 1.236846 \tValidation Loss: 1.055822 \n",
    "Epoch: 2 \tAccuracy: 0.623366 \tTraining Loss: 0.961489 \tValidation Loss: 0.905803 \n",
    "Epoch: 3 \tAccuracy: 0.622854 \tTraining Loss: 0.848723 \tValidation Loss: 0.916030 \n",
    "Epoch: 4 \tAccuracy: 0.663153 \tTraining Loss: 0.810521 \tValidation Loss: 0.839140 \n",
    "Epoch: 5 \tAccuracy: 0.678538 \tTraining Loss: 0.719327 \tValidation Loss: 0.799447 \n",
    "Epoch: 6 \tAccuracy: 0.666027 \tTraining Loss: 0.662806 \tValidation Loss: 0.839970 \n",
    "Epoch: 7 \tAccuracy: 0.673515 \tTraining Loss: 0.614681 \tValidation Loss: 0.834663 \n",
    "Epoch: 8 \tAccuracy: 0.686119 \tTraining Loss: 0.533959 \tValidation Loss: 0.794181 \n",
    "Epoch: 9 \tAccuracy: 0.696665 \tTraining Loss: 0.458621 \tValidation Loss: 0.787878 \n",
    "Epoch: 10 \tAccuracy: 0.700619 \tTraining Loss: 0.413524 \tValidation Loss: 0.756762 \n",
    "Final Results:\tAccuracy: 0.492397 \tTraining Loss: 0.442663 \tTesting Loss: 1.396512 \n",
    "\n",
    "\n",
    "Loss Function: NLLLoss \tNumber of Epochs: 10 \tBatch Size: 800 \tValidation Percent: 0.2\n",
    "Images resized to 30x40px.\n",
    "Beginning setup...\n",
    "Setting up train, test, and validation sets...\n",
    "Full train set size:  9957\n",
    "Train set size:  7966\n",
    "Validation set size:  1991\n",
    "Test set size:  2487\n",
    "Beginning training...\n",
    "Epoch: 1 \tAccuracy: 0.475972 \tTraining Loss: 1.314685 \tValidation Loss: 1.238930 \n",
    "Epoch: 2 \tAccuracy: 0.574277 \tTraining Loss: 1.098886 \tValidation Loss: 1.051863 \n",
    "Epoch: 3 \tAccuracy: 0.589053 \tTraining Loss: 0.974349 \tValidation Loss: 0.978190 \n",
    "Epoch: 4 \tAccuracy: 0.635212 \tTraining Loss: 0.904811 \tValidation Loss: 0.916149 \n",
    "Epoch: 5 \tAccuracy: 0.646122 \tTraining Loss: 0.843347 \tValidation Loss: 0.872921 \n",
    "Epoch: 6 \tAccuracy: 0.644417 \tTraining Loss: 0.789788 \tValidation Loss: 0.870462 \n",
    "Epoch: 7 \tAccuracy: 0.650500 \tTraining Loss: 0.748503 \tValidation Loss: 0.880995 \n",
    "Epoch: 8 \tAccuracy: 0.655006 \tTraining Loss: 0.694173 \tValidation Loss: 0.856772 \n",
    "Epoch: 9 \tAccuracy: 0.650610 \tTraining Loss: 0.655904 \tValidation Loss: 0.895626 \n",
    "Epoch: 10 \tAccuracy: 0.670179 \tTraining Loss: 0.624158 \tValidation Loss: 0.838727 \n",
    "Final Results:\tAccuracy: 0.539670 \tTraining Loss: 0.630354 \tTesting Loss: 1.293276 \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMytA1uPAf62"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DSP 461 Final Project(v5).ipynb",
   "provenance": [
    {
     "file_id": "1fF72BlAm7vwFnC9cCnAjMHb_0ZhK23wy",
     "timestamp": 1575498877653
    },
    {
     "file_id": "1yyL8Uo9SzZhV6HtAEuEGPYNoUlOYa3aK",
     "timestamp": 1574796892120
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

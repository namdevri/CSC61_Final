{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSP 461 Final Project(v4).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXLMLqmhqGqt",
        "colab_type": "code",
        "outputId": "5e7cd09a-1667-46d2-c888-7fe6fdb4a939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "#mount your drive.  Complete Oauth to authenticate\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqJt5FExqfYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip image folder\n",
        "!unzip -uq \"/content/gdrive/My Drive/jpegs.zip\" -d \"/content/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA-s2tHpDc2e",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC81Yd_KrO5M",
        "colab_type": "code",
        "outputId": "811b5d33-2e22-40db-dcf0-f3ac8b379e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Training set values (same for all data)\n",
        "data_means = [0.6786, 0.6413, 0.6605]\n",
        "data_stds = [0.2012, 0.2080, 0.1997]\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "#    transforms.Resize(255),\n",
        "#    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),  # Transforms channels from 0- 255 -> 0-1.\n",
        "    transforms.Normalize(mean=data_means, std=data_stds)])\n",
        "\n",
        "full_train_set = datasets.ImageFolder(\"/content/gdrive/My Drive/TRAIN\", transform=transformations)\n",
        "full_train_set, temp = torch.utils.data.random_split(full_train_set, [int(len(full_train_set) / 20), len(full_train_set) - int(len(full_train_set) / 20)])\n",
        "full_train_loader = torch.utils.data.DataLoader(full_train_set, batch_size=25, shuffle=True)\n",
        "print(\"Train set size: \", len(full_train_set))\n",
        "\n",
        "#train_set_E = datasets.ImageFolder(\"/content/gdrive/My Drive/TRAIN/EOSINOPHIL\", transform=transformations)\n",
        "#train_set_L = datasets.ImageFolder(\"/content/gdrive/My Drive/TRAIN/LYMPHOCYTE\", transform=transformations)\n",
        "#train_set_M = datasets.ImageFolder(\"/content/gdrive/My Drive/TRAIN/MONOCYTE\", transform=transformations)\n",
        "#train_set_N = datasets.ImageFolder(\"/content/gdrive/My Drive/TRAIN/NEUTROPHIL\", transform=transformations)\n",
        "\n",
        "test_set = datasets.ImageFolder(\"/content/gdrive/My Drive/TEST\", transform=transformations)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size =25, shuffle=True)\n",
        "\n",
        "# Options: MOST GENERALIZED - 121, 169, 201, 161 - MOST ACCURATE\n",
        "# https://pytorch.org/hub/pytorch_vision_densenet/\n",
        "model = models.densenet161(pretrained=True)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "classifier_input = model.classifier.in_features\n",
        "num_labels = 4\n",
        "classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(1024, 512),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(512, num_labels),\n",
        "                           nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "model.classifier = classifier\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Can choose various loss functions to use.\n",
        "criterion = nn.NLLLoss()\n",
        "# Set the optimizer function using torch.optim as optim library\n",
        "optimizer = optim.Adam(model.classifier.parameters())\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    ep_train_loss = 0\n",
        "    ep_val_loss = 0\n",
        "    ep_accuracy = 0\n",
        "\n",
        "    for i in range(num_folds):\n",
        "\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # Constructing training and validation sets\n",
        "        num_folds = 5\n",
        "        folds = []\n",
        "        items = full_train_set\n",
        "        for j in range(num_folds):\n",
        "            fold_length = int(len(items) / (1.*num_folds - j))\n",
        "            items, new_fold = torch.utils.data.random_split(items, [len(items) - fold_length, fold_length])\n",
        "            folds.append(new_fold)\n",
        "\n",
        "        train_set = -1\n",
        "        for j in range(num_folds):\n",
        "            if j != i:\n",
        "                if train_set == -1:\n",
        "                    train_set = folds[j]\n",
        "                else:\n",
        "                    train_set = torch.utils.data.ConcatDataset([train_set, folds[j]])\n",
        "        val_set = folds[i]\n",
        "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=25, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=25, shuffle=True)\n",
        "\n",
        "        # Training the model\n",
        "        model.train()\n",
        "        counter = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move to device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Clear optimizers\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            output = model.forward(inputs)\n",
        "            # Loss\n",
        "            loss = criterion(output, labels)\n",
        "            # Calculate gradients (backpropogation)\n",
        "            loss.backward()\n",
        "            # Adjust parameters based on gradients\n",
        "            optimizer.step()\n",
        "            # Add the loss to the training set's rnning loss\n",
        "            train_loss += loss.item()*inputs.size(0)\n",
        "\n",
        "            # Print the progress of our training\n",
        "            counter += 1\n",
        "            print(counter, \"/\", len(train_loader))\n",
        "\n",
        "        # Evaluating the model\n",
        "        model.eval()\n",
        "        counter = 0\n",
        "        # Tell torch not to calculate gradients\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                # Move to device\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                # Forward pass\n",
        "                output = model.forward(inputs)\n",
        "                # Calculate Loss\n",
        "                valloss = criterion(output, labels)\n",
        "                # Add loss to the validation set's running loss\n",
        "                val_loss += valloss.item()*inputs.size(0)\n",
        "\n",
        "                # Since our model outputs a LogSoftmax, find the real\n",
        "                # percentages by reversing the log function\n",
        "                output = torch.exp(output)\n",
        "                # Get the top class of the output\n",
        "                top_p, top_class = output.topk(1, dim=1)\n",
        "                # See how many of the classes were correct?\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                # Calculate the mean (get the accuracy for this batch)\n",
        "                # and add it to the running accuracy for this epoch\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "                # Print the progress of our evaluation\n",
        "                counter += 1\n",
        "                print(counter, \"/\", len(val_loader))\n",
        "\n",
        "        # Get the average loss for the entire fold\n",
        "        train_loss = train_loss/len(train_loader.dataset)\n",
        "        val_loss = val_loss/len(val_loader.dataset)\n",
        "        accuracy = accuracy/len(val_loader)\n",
        "        # Add to epoch's running total for avg losses\n",
        "        ep_train_loss += train_loss\n",
        "        ep_val_loss += val_loss\n",
        "        ep_accuracy += accuracy\n",
        "        # Print out the information\n",
        "        print('\\nFold Accuracy: ', accuracy)\n",
        "        print('Epoch: {} \\tFold: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\n'.format(epoch, i, train_loss, val_loss))\n",
        "\n",
        "    # Get the average loss for the entire fold\n",
        "    ep_train_loss = ep_train_loss/num_folds\n",
        "    ep_val_loss = ep_val_loss/num_folds\n",
        "    ep_accuracy = ep_accuracy/num_folds\n",
        "    # Print out the information\n",
        "    print('\\n\\t*** Epoch Accuracy: ', ep_accuracy)\n",
        "    print('\\t*** Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\n'.format(epoch, ep_train_loss, ep_val_loss))\n",
        "\n",
        "\n",
        "full_train_loss = 0\n",
        "test_loss = 0\n",
        "test_accuracy = 0\n",
        "\n",
        "# Training the model one final time on the full dataset\n",
        "model.train()\n",
        "counter = 0\n",
        "for inputs, labels in full_train_loader:\n",
        "    # Move to device\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    # Clear optimizers\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    output = model.forward(inputs)\n",
        "    # Loss\n",
        "    loss = criterion(output, labels)\n",
        "    # Calculate gradients (backpropogation)\n",
        "    loss.backward()\n",
        "    # Adjust parameters based on gradients\n",
        "    optimizer.step()\n",
        "    # Add the loss to the training set's rnning loss\n",
        "    full_train_loss += loss.item()*inputs.size(0)\n",
        "\n",
        "    # Print the progress of our training\n",
        "    counter += 1\n",
        "    print(counter, \"/\", len(full_train_loader))\n",
        "\n",
        "# Saving the model\n",
        "torch.save(model, \"./blood_model.py\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "counter = 0\n",
        "# Tell torch not to calculate gradients\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move to device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Forward pass\n",
        "        output = model.forward(inputs)\n",
        "        # Calculate Loss\n",
        "        testloss = criterion(output, labels)\n",
        "        # Add loss to the validation set's running loss\n",
        "        test_loss += testloss.item()*inputs.size(0)\n",
        "\n",
        "        # Since our model outputs a LogSoftmax, find the real\n",
        "        # percentages by reversing the log function\n",
        "        output = torch.exp(output)\n",
        "        # Get the top class of the output\n",
        "        top_p, top_class = output.topk(1, dim=1)\n",
        "        # See how many of the classes were correct?\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        # Calculate the mean (get the accuracy for this batch)\n",
        "        # and add it to the running accuracy for this epoch\n",
        "        test_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        # Print the progress of our evaluation\n",
        "        counter += 1\n",
        "        print(counter, \"/\", len(test_loader))\n",
        "\n",
        "# Get the average loss for the entire fold\n",
        "full_train_loss = full_train_loss/len(full_train_loader.dataset)\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "test_accuracy = test_accuracy/len(test_loader)\n",
        "# Print out the information\n",
        "print('Test Set Accuracy: ', test_accuracy)\n",
        "print('Training Loss: {:.6f} \\tTesting Loss: {:.6f} \\n'.format(full_train_loss, test_loss))\n",
        "\n",
        "\n",
        "# Process our image\n",
        "def process_image(image_path):\n",
        "    # Load Image\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Get the dimensions of the image\n",
        "    width, height = img.size\n",
        "\n",
        "    # Resize by keeping the aspect ratio, but changing the dimension\n",
        "    # so the shortest size is 255px\n",
        "    # img = img.resize((255, int(255*(height/width))) if width < height else (int(255*(width/height)), 255))\n",
        "\n",
        "    # Get the dimensions of the new image size\n",
        "    width, height = img.size\n",
        "\n",
        "    # Set the coordinates to do a center crop of 224 x 224\n",
        "    #left = (width - 224)/2\n",
        "    #top = (height - 224)/2\n",
        "    #right = (width + 224)/2\n",
        "    #bottom = (height + 224)/2\n",
        "    #img = img.crop((left, top, right, bottom))\n",
        "\n",
        "    # Turn image into numpy array\n",
        "    img = np.array(img)\n",
        "\n",
        "    # Make the color channel dimension first instead of last\n",
        "    img = img.transpose((2, 0, 1))\n",
        "\n",
        "    # Make all values between 0 and 1\n",
        "    img = img/255\n",
        "\n",
        "    # Normalize based on the preset mean and standard deviation\n",
        "    img[0] = (img[0] - data_means[0])/data_stds[0]\n",
        "    img[1] = (img[1] - data_means[1])/data_stds[1]\n",
        "    img[2] = (img[2] - data_means[2])/data_stds[2]\n",
        "\n",
        "    # Add a fourth dimension to the beginning to indicate batch size\n",
        "    img = img[np.newaxis,:]\n",
        "\n",
        "    # Turn into a torch tensor\n",
        "    image = torch.from_numpy(img)\n",
        "    image = image.float()\n",
        "    return image\n",
        "\n",
        "# Using our model to predict the label\n",
        "def predict(image, model):\n",
        "    # Pass the image through our model\n",
        "    output = model.forward(image)\n",
        "\n",
        "    # Reverse the log function in our output\n",
        "    output = torch.exp(output)\n",
        "\n",
        "    # Get the top predicted class, and the output percentage for\n",
        "    # that class\n",
        "    probs, classes = output.topk(1, dim=1)\n",
        "    return probs.item(), classes.item()\n",
        "\n",
        "# Show Image\n",
        "def show_image(image):\n",
        "    # Convert image to numpy\n",
        "    image = image.numpy()\n",
        "\n",
        "    # Un-normalize the image with avg std and mean\n",
        "    image[0] = image[0] * 0.2030 + 0.6601\n",
        "\n",
        "    # Print the image\n",
        "    fig = plt.figure(figsize=(25, 4))\n",
        "    plt.imshow(np.transpose(image[0], (1, 2, 0)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set size:  497\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.25000000186264515\n",
            "Epoch: 0 \tFold: 4 \tTraining Loss: 1.385595 \tValidation Loss: 1.382909 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.3500000014901161\n",
            "Epoch: 0 \tFold: 4 \tTraining Loss: 1.334669 \tValidation Loss: 1.252008 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.5500000044703484\n",
            "Epoch: 0 \tFold: 4 \tTraining Loss: 1.152502 \tValidation Loss: 0.969666 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.4399999976158142\n",
            "Epoch: 0 \tFold: 4 \tTraining Loss: 1.101131 \tValidation Loss: 1.194316 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.4699999913573265\n",
            "Epoch: 0 \tFold: 4 \tTraining Loss: 1.138722 \tValidation Loss: 0.993968 \n",
            "\n",
            "\n",
            "\t*** Epoch Accuracy:  0.4119999993592501\n",
            "\t*** Epoch: 0 \tTraining Loss: 1.222524 \tValidation Loss: 1.158573 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.6899999976158142\n",
            "Epoch: 1 \tFold: 4 \tTraining Loss: 0.880027 \tValidation Loss: 0.745272 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.760000005364418\n",
            "Epoch: 1 \tFold: 4 \tTraining Loss: 0.934315 \tValidation Loss: 0.619029 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.7699999958276749\n",
            "Epoch: 1 \tFold: 4 \tTraining Loss: 0.744513 \tValidation Loss: 0.579443 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8100000023841858\n",
            "Epoch: 1 \tFold: 4 \tTraining Loss: 0.566435 \tValidation Loss: 0.480685 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.800000011920929\n",
            "Epoch: 1 \tFold: 4 \tTraining Loss: 0.576853 \tValidation Loss: 0.567472 \n",
            "\n",
            "\n",
            "\t*** Epoch Accuracy:  0.7660000026226044\n",
            "\t*** Epoch: 1 \tTraining Loss: 0.740429 \tValidation Loss: 0.598380 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8100000023841858\n",
            "Epoch: 2 \tFold: 4 \tTraining Loss: 0.510391 \tValidation Loss: 0.382622 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8500000089406967\n",
            "Epoch: 2 \tFold: 4 \tTraining Loss: 0.471188 \tValidation Loss: 0.391805 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8700000047683716\n",
            "Epoch: 2 \tFold: 4 \tTraining Loss: 0.387955 \tValidation Loss: 0.286399 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8700000047683716\n",
            "Epoch: 2 \tFold: 4 \tTraining Loss: 0.270960 \tValidation Loss: 0.340364 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.7699999958276749\n",
            "Epoch: 2 \tFold: 4 \tTraining Loss: 0.470267 \tValidation Loss: 0.522501 \n",
            "\n",
            "\n",
            "\t*** Epoch Accuracy:  0.8340000033378601\n",
            "\t*** Epoch: 2 \tTraining Loss: 0.422152 \tValidation Loss: 0.384738 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.949999988079071\n",
            "Epoch: 3 \tFold: 4 \tTraining Loss: 0.368403 \tValidation Loss: 0.186596 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.9699999839067459\n",
            "Epoch: 3 \tFold: 4 \tTraining Loss: 0.238804 \tValidation Loss: 0.137139 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.9099999815225601\n",
            "Epoch: 3 \tFold: 4 \tTraining Loss: 0.215327 \tValidation Loss: 0.179104 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.9399999976158142\n",
            "Epoch: 3 \tFold: 4 \tTraining Loss: 0.225227 \tValidation Loss: 0.166410 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.9599999934434891\n",
            "Epoch: 3 \tFold: 4 \tTraining Loss: 0.371254 \tValidation Loss: 0.120329 \n",
            "\n",
            "\n",
            "\t*** Epoch Accuracy:  0.9459999889135361\n",
            "\t*** Epoch: 3 \tTraining Loss: 0.283803 \tValidation Loss: 0.157915 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8699999898672104\n",
            "Epoch: 4 \tFold: 4 \tTraining Loss: 0.303564 \tValidation Loss: 0.361932 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.9199999868869781\n",
            "Epoch: 4 \tFold: 4 \tTraining Loss: 0.441210 \tValidation Loss: 0.244060 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.8699999898672104\n",
            "Epoch: 4 \tFold: 4 \tTraining Loss: 0.214605 \tValidation Loss: 0.290270 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.9399999976158142\n",
            "Epoch: 4 \tFold: 4 \tTraining Loss: 0.269165 \tValidation Loss: 0.186354 \n",
            "\n",
            "1 / 16\n",
            "2 / 16\n",
            "3 / 16\n",
            "4 / 16\n",
            "5 / 16\n",
            "6 / 16\n",
            "7 / 16\n",
            "8 / 16\n",
            "9 / 16\n",
            "10 / 16\n",
            "11 / 16\n",
            "12 / 16\n",
            "13 / 16\n",
            "14 / 16\n",
            "15 / 16\n",
            "16 / 16\n",
            "1 / 4\n",
            "2 / 4\n",
            "3 / 4\n",
            "4 / 4\n",
            "\n",
            "Fold Accuracy:  0.7999999970197678\n",
            "Epoch: 4 \tFold: 4 \tTraining Loss: 0.278700 \tValidation Loss: 0.372667 \n",
            "\n",
            "\n",
            "\t*** Epoch Accuracy:  0.8799999922513961\n",
            "\t*** Epoch: 4 \tTraining Loss: 0.301449 \tValidation Loss: 0.291056 \n",
            "\n",
            "1 / 20\n",
            "2 / 20\n",
            "3 / 20\n",
            "4 / 20\n",
            "5 / 20\n",
            "6 / 20\n",
            "7 / 20\n",
            "8 / 20\n",
            "9 / 20\n",
            "10 / 20\n",
            "11 / 20\n",
            "12 / 20\n",
            "13 / 20\n",
            "14 / 20\n",
            "15 / 20\n",
            "16 / 20\n",
            "17 / 20\n",
            "18 / 20\n",
            "19 / 20\n",
            "20 / 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseLayer. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _Transition. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 / 100\n",
            "2 / 100\n",
            "3 / 100\n",
            "4 / 100\n",
            "5 / 100\n",
            "6 / 100\n",
            "7 / 100\n",
            "8 / 100\n",
            "9 / 100\n",
            "10 / 100\n",
            "11 / 100\n",
            "12 / 100\n",
            "13 / 100\n",
            "14 / 100\n",
            "15 / 100\n",
            "16 / 100\n",
            "17 / 100\n",
            "18 / 100\n",
            "19 / 100\n",
            "20 / 100\n",
            "21 / 100\n",
            "22 / 100\n",
            "23 / 100\n",
            "24 / 100\n",
            "25 / 100\n",
            "26 / 100\n",
            "27 / 100\n",
            "28 / 100\n",
            "29 / 100\n",
            "30 / 100\n",
            "31 / 100\n",
            "32 / 100\n",
            "33 / 100\n",
            "34 / 100\n",
            "35 / 100\n",
            "36 / 100\n",
            "37 / 100\n",
            "38 / 100\n",
            "39 / 100\n",
            "40 / 100\n",
            "41 / 100\n",
            "42 / 100\n",
            "43 / 100\n",
            "44 / 100\n",
            "45 / 100\n",
            "46 / 100\n",
            "47 / 100\n",
            "48 / 100\n",
            "49 / 100\n",
            "50 / 100\n",
            "51 / 100\n",
            "52 / 100\n",
            "53 / 100\n",
            "54 / 100\n",
            "55 / 100\n",
            "56 / 100\n",
            "57 / 100\n",
            "58 / 100\n",
            "59 / 100\n",
            "60 / 100\n",
            "61 / 100\n",
            "62 / 100\n",
            "63 / 100\n",
            "64 / 100\n",
            "65 / 100\n",
            "66 / 100\n",
            "67 / 100\n",
            "68 / 100\n",
            "69 / 100\n",
            "70 / 100\n",
            "71 / 100\n",
            "72 / 100\n",
            "73 / 100\n",
            "74 / 100\n",
            "75 / 100\n",
            "76 / 100\n",
            "77 / 100\n",
            "78 / 100\n",
            "79 / 100\n",
            "80 / 100\n",
            "81 / 100\n",
            "82 / 100\n",
            "83 / 100\n",
            "84 / 100\n",
            "85 / 100\n",
            "86 / 100\n",
            "87 / 100\n",
            "88 / 100\n",
            "89 / 100\n",
            "90 / 100\n",
            "91 / 100\n",
            "92 / 100\n",
            "93 / 100\n",
            "94 / 100\n",
            "95 / 100\n",
            "96 / 100\n",
            "97 / 100\n",
            "98 / 100\n",
            "99 / 100\n",
            "100 / 100\n",
            "\n",
            "Overall Training Set Accuracy:  0.0\n",
            "Test Set Accuracy:  0.5566333338618279\n",
            "Training Loss: 0.293932 \tTesting Loss: 1.363801 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv8vq8UPnTHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}